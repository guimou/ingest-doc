{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redhat_documentation import RedHatDocumentationLoader\n",
    "from langchain_community.document_transformers import Html2TextTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/introduction_to_red_hat_openshift_ai/index\"]\n",
    "loader = RedHatDocumentationLoader(urls)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"doc-wrapper pvof-doc__wrapper j-superdoc__content-wrapper\" id=\"doc-wrapper\">\\n<div>\\n<h1 itemprop=\"name\">Introduction to Red Hat OpenShift AI</h1>\\n</div>\\n<div id=\"idm140658606811920\" xml:lang=\"en-US\"><div><div><div>Red Hat OpenShift AI Self-Managed 2-latest</div><div><h2>OpenShift AI is a platform for data scientists and developers of artificial intelligence and machine learning (AI/ML) applications</h2></div><div>Legal Notice</div><div><div>Abstract<div>\\nRed Hat OpenShift AI is a platform for data scientists and developers of artificial intelligence and machine learning applications.\\n</div></div></div></div><hr/></div><div><div><div><h1>Chapter 1. Overview of OpenShift AI</h1></div></div></div>\\nUsing Red Hat OpenShift AI, users can integrate data, artificial intelligence and machine learning software to execute end-to-end machine learning workflows. OpenShift AI is supported in two configurations:\\n<div> 1. Installed as an Add-on to a Red Hat managed environment such as Red Hat OpenShift Dedicated and Red Hat OpenShift Service on Amazon Web Services (ROSA).\\n 2. Installed as a self-managed Operator on a self-managed environment, such as Red Hat OpenShift Container Platform.\\n</div>\\nFor data scientists, OpenShift AI includes Jupyter and a collection of default notebook images optimized with the tools and libraries required for model development, and the TensorFlow and PyTorch frameworks. Deploy and host your models, integrate models into external applications, and export models to host them in any hybrid cloud environment. You can also accelerate your data science experiments through the use of graphics processing units (GPUs) and Habana Gaudi devices.\\n\\nFor administrators, OpenShift AI enables data science workloads in an existing Red Hat OpenShift or ROSA environment. Manage users with your existing OpenShift identity provider, and manage the resources available to notebook servers to ensure data scientists have what they require to create, train, and host models. Use accelerators to reduce costs and allow your data scientists to enhance the performance of their end-to-end data science workflows using graphics processing units (GPUs) and Habana Gaudi devices.\\n\\nOpenShift AI offers two distributions:\\n<div> - A managed cloud service add-on for Red Hat OpenShift Dedicated (with a Customer Cloud Subscription for AWS or GCP) or for Red Hat OpenShift Service on Amazon Web Services (ROSA).For information about OpenShift AI on a Red Hat managed environment, see Product Documentation for Red Hat OpenShift AI.\\n - Self-managed software that you can install on-premise or on the public cloud in a self-managed environment, such as OpenShift Container Platform.For information about OpenShift AI as self-managed software on your OpenShift cluster in a connected or a disconnected environment, see Product Documentation for Red Hat OpenShift AI Self-Managed.\\n</div>\\nFor information about OpenShift AI supported software platforms, components, and dependencies, see Supported configurations.\\n<div><div><div><h1>Chapter 2. Product features</h1></div></div></div>\\nRed Hat OpenShift AI provides several features for data scientists and IT operations administrators.\\n<div><div><div><h2>2.1. Features for data scientists</h2></div></div></div><div><h4>Containers</h4>While tools such as JupyterLab already offer intuitive ways for data scientists to develop models on their machines, there are always inherent complexities involved with collaboration and sharing work. Moreover, using specialized hardware such as powerful GPUs can be very expensive when you have to buy and maintain your own. The Jupyter environment that is included with OpenShift AI lets you take your development environment anywhere you need it to be. Because all of the workloads are run as containers, collaboration is as easy as sharing an image with your team members, or even simply adding it to the list of default containers that they can use. As a result, GPUs and large amounts of memory are significantly more accessible, since you are no longer limited by what your laptop can support.<h4>Integration with third-party machine learning tools</h4>We have all run into situations where our favorite tools or services do not play well with one another. OpenShift AI is designed with flexibility in mind. You can use a wide range of open source and third-party tools with OpenShift AI. These tools support the complete machine learning lifecycle, from data engineering and feature extraction to model deployment and management.<h4>Collaboration on notebooks with Git</h4>Use Jupyter’s Git interface to work collaboratively with others, and keep good track of the changes to your code.<h4>Securely built notebook images</h4>Choose from a default set of notebook images that are pre-configured with the tools and libraries that you need for model development. Software stacks, especially those involved in machine learning, tend to be complex systems. There are many modules and libraries in the Python ecosystem that can be used, so determining which versions of what libraries to use can be very challenging. OpenShift AI includes many packaged notebook images that have been built with insight from data scientists and recommendation engines. You can start new projects quickly on the right foot without worrying about downloading unproven and possibly insecure images from random upstream repositories.<h4>Custom notebooks</h4>In addition to notebook images provided and supported by Red Hat and independent software vendors (ISVs), you can configure custom notebook images that cater to your project’s specific requirements.<h4>Data science pipelines</h4>OpenShift AI supports data science pipelines for a mature and efficient way of running your data science workloads. You can standardize and automate machine learning workflows that enable you to develop and deploy your data science models.<h4>Model serving</h4>As a data scientist, you can deploy your trained machine-learning models to serve intelligent applications in production. Deploying or serving a model makes the model’s functions available as a service endpoint that can be used for testing or integration into applications. You have much control over how this serving is performed.</div><div><h4>Optimize your data science models with accelerators</h4>If you work with large data sets, you can optimize the performance of your data science models in OpenShift AI with NVIDIA graphics processing units (GPUs) or Habana Gaudi devices. Accelerators enable you to scale your work, reduce latency, and increase productivity.</div><div><div><div><h2>2.2. Features for IT Operations administrators</h2></div></div></div><div><h4>Manage users with an identity provider</h4>OpenShift AI supports the same authentication systems as your OpenShift cluster. By default, OpenShift AI is accessible to all users listed in your identity provider and those users do not need a separate set of credentials to access OpenShift AI. Optionally, you can limit the set of users who have access by creating an OpenShift group that specifies a subset of users. You can also create an OpenShift group that identifies the list of users who have administrator access to OpenShift AI.<h4>Manage resources with OpenShift</h4>Use your existing OpenShift knowledge to configure and manage resources for your OpenShift AI users.<h4>Control Red Hat usage data collection</h4>Choose whether to allow Red Hat to collect data about OpenShift AI usage in your cluster. Usage data collection is enabled by default when you install OpenShift AI on your OpenShift cluster.<h4>Apply autoscaling to your cluster to reduce usage costs</h4>Use the cluster autoscaler to adjust the size of your cluster to meet its current needs and optimize costs.<h4>Manage resource usage by stopping idle notebooks</h4>Reduce resource usage in your OpenShift AI deployment by automatically stopping notebook servers that have been idle for a period of time.<h4>Implement model-serving runtimes</h4>OpenShift AI provides support for model-serving runtimes. A model-serving runtime provides integration with a specified model server and the model frameworks that it supports. By default, OpenShift AI includes the OpenVINO Model Server runtime. However, if this runtime doesn’t meet your needs (for example, if it doesn’t support a particular model framework), you can add your own custom runtimes.<h4>Install in a disconnected environment</h4>OpenShift AI Self-Managed supports installation in a disconnected environment. Disconnected clusters are on a restricted network, typically behind a firewall and unable to reach the Internet. In this case, clusters cannot access the remote registries where Red Hat provided OperatorHub sources reside. In this case, you deploy the OpenShift AI Operator to a disconnected environment by using a private registry in which you have mirrored (copied) the relevant images.<h4>Manage accelerators</h4>Enable NVIDIA graphics processing units (GPUs) or Habana Gaudi devices in OpenShift AI and allow your data scientists to use compute-heavy workloads.</div><div><div><div><h1>Chapter 3. Try It</h1></div></div></div>\\nData scientists and developers can try OpenShift AI and access tutorials and activities in the Red Hat Developer sandbox environment.\\n\\nIT operations administrators can try OpenShift AI in your own cluster with a 60-day product trial.\\n<div><div><div><h1>Chapter 4. Get It</h1></div></div></div><div><h4>Managed cloud service</h4>You have the following options for subscribing to OpenShift AI as a managed service: - For OpenShift Dedicated, subscribe through Red Hat. - For Red Hat OpenShift Service on Amazon Web Services (ROSA), subscribe through Red Hat or subscribe through the AWS Marketplace.<h4>Self-managed software</h4>To get Red Hat OpenShift AI as self-managed software, sign up for it with your Red Hat account team.</div><div></div></div>\\n\\n</div>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='# Introduction to Red Hat OpenShift AI\\n\\nRed Hat OpenShift AI Self-Managed 2-latest\\n\\n## OpenShift AI is a platform for data scientists and developers of artificial\\nintelligence and machine learning (AI/ML) applications\\n\\nLegal Notice\\n\\nAbstract\\n\\nRed Hat OpenShift AI is a platform for data scientists and developers of\\nartificial intelligence and machine learning applications.\\n\\n* * *\\n\\n# Chapter 1. Overview of OpenShift AI\\n\\nUsing Red Hat OpenShift AI, users can integrate data, artificial intelligence\\nand machine learning software to execute end-to-end machine learning\\nworkflows. OpenShift AI is supported in two configurations:\\n\\n1\\\\. Installed as an Add-on to a Red Hat managed environment such as Red Hat\\nOpenShift Dedicated and Red Hat OpenShift Service on Amazon Web Services\\n(ROSA). 2\\\\. Installed as a self-managed Operator on a self-managed\\nenvironment, such as Red Hat OpenShift Container Platform.\\n\\nFor data scientists, OpenShift AI includes Jupyter and a collection of default\\nnotebook images optimized with the tools and libraries required for model\\ndevelopment, and the TensorFlow and PyTorch frameworks. Deploy and host your\\nmodels, integrate models into external applications, and export models to host\\nthem in any hybrid cloud environment. You can also accelerate your data\\nscience experiments through the use of graphics processing units (GPUs) and\\nHabana Gaudi devices. For administrators, OpenShift AI enables data science\\nworkloads in an existing Red Hat OpenShift or ROSA environment. Manage users\\nwith your existing OpenShift identity provider, and manage the resources\\navailable to notebook servers to ensure data scientists have what they require\\nto create, train, and host models. Use accelerators to reduce costs and allow\\nyour data scientists to enhance the performance of their end-to-end data\\nscience workflows using graphics processing units (GPUs) and Habana Gaudi\\ndevices. OpenShift AI offers two distributions:\\n\\n\\\\- A managed cloud service add-on for Red Hat OpenShift Dedicated (with a\\nCustomer Cloud Subscription for AWS or GCP) or for Red Hat OpenShift Service\\non Amazon Web Services (ROSA).For information about OpenShift AI on a Red Hat\\nmanaged environment, see Product Documentation for Red Hat OpenShift AI. \\\\-\\nSelf-managed software that you can install on-premise or on the public cloud\\nin a self-managed environment, such as OpenShift Container Platform.For\\ninformation about OpenShift AI as self-managed software on your OpenShift\\ncluster in a connected or a disconnected environment, see Product\\nDocumentation for Red Hat OpenShift AI Self-Managed.\\n\\nFor information about OpenShift AI supported software platforms, components,\\nand dependencies, see Supported configurations.\\n\\n# Chapter 2. Product features\\n\\nRed Hat OpenShift AI provides several features for data scientists and IT\\noperations administrators.\\n\\n## 2.1. Features for data scientists\\n\\n#### Containers\\n\\nWhile tools such as JupyterLab already offer intuitive ways for data\\nscientists to develop models on their machines, there are always inherent\\ncomplexities involved with collaboration and sharing work. Moreover, using\\nspecialized hardware such as powerful GPUs can be very expensive when you have\\nto buy and maintain your own. The Jupyter environment that is included with\\nOpenShift AI lets you take your development environment anywhere you need it\\nto be. Because all of the workloads are run as containers, collaboration is as\\neasy as sharing an image with your team members, or even simply adding it to\\nthe list of default containers that they can use. As a result, GPUs and large\\namounts of memory are significantly more accessible, since you are no longer\\nlimited by what your laptop can support.\\n\\n#### Integration with third-party machine learning tools\\n\\nWe have all run into situations where our favorite tools or services do not\\nplay well with one another. OpenShift AI is designed with flexibility in mind.\\nYou can use a wide range of open source and third-party tools with OpenShift\\nAI. These tools support the complete machine learning lifecycle, from data\\nengineering and feature extraction to model deployment and management.\\n\\n#### Collaboration on notebooks with Git\\n\\nUse Jupyter’s Git interface to work collaboratively with others, and keep good\\ntrack of the changes to your code.\\n\\n#### Securely built notebook images\\n\\nChoose from a default set of notebook images that are pre-configured with the\\ntools and libraries that you need for model development. Software stacks,\\nespecially those involved in machine learning, tend to be complex systems.\\nThere are many modules and libraries in the Python ecosystem that can be used,\\nso determining which versions of what libraries to use can be very\\nchallenging. OpenShift AI includes many packaged notebook images that have\\nbeen built with insight from data scientists and recommendation engines. You\\ncan start new projects quickly on the right foot without worrying about\\ndownloading unproven and possibly insecure images from random upstream\\nrepositories.\\n\\n#### Custom notebooks\\n\\nIn addition to notebook images provided and supported by Red Hat and\\nindependent software vendors (ISVs), you can configure custom notebook images\\nthat cater to your project’s specific requirements.\\n\\n#### Data science pipelines\\n\\nOpenShift AI supports data science pipelines for a mature and efficient way of\\nrunning your data science workloads. You can standardize and automate machine\\nlearning workflows that enable you to develop and deploy your data science\\nmodels.\\n\\n#### Model serving\\n\\nAs a data scientist, you can deploy your trained machine-learning models to\\nserve intelligent applications in production. Deploying or serving a model\\nmakes the model’s functions available as a service endpoint that can be used\\nfor testing or integration into applications. You have much control over how\\nthis serving is performed.\\n\\n#### Optimize your data science models with accelerators\\n\\nIf you work with large data sets, you can optimize the performance of your\\ndata science models in OpenShift AI with NVIDIA graphics processing units\\n(GPUs) or Habana Gaudi devices. Accelerators enable you to scale your work,\\nreduce latency, and increase productivity.\\n\\n## 2.2. Features for IT Operations administrators\\n\\n#### Manage users with an identity provider\\n\\nOpenShift AI supports the same authentication systems as your OpenShift\\ncluster. By default, OpenShift AI is accessible to all users listed in your\\nidentity provider and those users do not need a separate set of credentials to\\naccess OpenShift AI. Optionally, you can limit the set of users who have\\naccess by creating an OpenShift group that specifies a subset of users. You\\ncan also create an OpenShift group that identifies the list of users who have\\nadministrator access to OpenShift AI.\\n\\n#### Manage resources with OpenShift\\n\\nUse your existing OpenShift knowledge to configure and manage resources for\\nyour OpenShift AI users.\\n\\n#### Control Red Hat usage data collection\\n\\nChoose whether to allow Red Hat to collect data about OpenShift AI usage in\\nyour cluster. Usage data collection is enabled by default when you install\\nOpenShift AI on your OpenShift cluster.\\n\\n#### Apply autoscaling to your cluster to reduce usage costs\\n\\nUse the cluster autoscaler to adjust the size of your cluster to meet its\\ncurrent needs and optimize costs.\\n\\n#### Manage resource usage by stopping idle notebooks\\n\\nReduce resource usage in your OpenShift AI deployment by automatically\\nstopping notebook servers that have been idle for a period of time.\\n\\n#### Implement model-serving runtimes\\n\\nOpenShift AI provides support for model-serving runtimes. A model-serving\\nruntime provides integration with a specified model server and the model\\nframeworks that it supports. By default, OpenShift AI includes the OpenVINO\\nModel Server runtime. However, if this runtime doesn’t meet your needs (for\\nexample, if it doesn’t support a particular model framework), you can add your\\nown custom runtimes.\\n\\n#### Install in a disconnected environment\\n\\nOpenShift AI Self-Managed supports installation in a disconnected environment.\\nDisconnected clusters are on a restricted network, typically behind a firewall\\nand unable to reach the Internet. In this case, clusters cannot access the\\nremote registries where Red Hat provided OperatorHub sources reside. In this\\ncase, you deploy the OpenShift AI Operator to a disconnected environment by\\nusing a private registry in which you have mirrored (copied) the relevant\\nimages.\\n\\n#### Manage accelerators\\n\\nEnable NVIDIA graphics processing units (GPUs) or Habana Gaudi devices in\\nOpenShift AI and allow your data scientists to use compute-heavy workloads.\\n\\n# Chapter 3. Try It\\n\\nData scientists and developers can try OpenShift AI and access tutorials and\\nactivities in the Red Hat Developer sandbox environment. IT operations\\nadministrators can try OpenShift AI in your own cluster with a 60-day product\\ntrial.\\n\\n# Chapter 4. Get It\\n\\n#### Managed cloud service\\n\\nYou have the following options for subscribing to OpenShift AI as a managed\\nservice: - For OpenShift Dedicated, subscribe through Red Hat. - For Red Hat\\nOpenShift Service on Amazon Web Services (ROSA), subscribe through Red Hat or\\nsubscribe through the AWS Marketplace.\\n\\n#### Self-managed software\\n\\nTo get Red Hat OpenShift AI as self-managed software, sign up for it with your\\nRed Hat account team.\\n\\n', metadata={'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/introduction_to_red_hat_openshift_ai/index'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "docs_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Red Hat OpenShift AI Self-Managed 2-latest', metadata={'Header 1': 'Introduction to Red Hat OpenShift AI'}),\n",
       " Document(page_content='intelligence and machine learning (AI/ML) applications  \\nLegal Notice  \\nAbstract  \\nRed Hat OpenShift AI is a platform for data scientists and developers of\\nartificial intelligence and machine learning applications.  \\n* * *', metadata={'Header 1': 'Introduction to Red Hat OpenShift AI', 'Header 2': 'OpenShift AI is a platform for data scientists and developers of artificial'}),\n",
       " Document(page_content='Using Red Hat OpenShift AI, users can integrate data, artificial intelligence\\nand machine learning software to execute end-to-end machine learning\\nworkflows. OpenShift AI is supported in two configurations:  \\n1\\\\. Installed as an Add-on to a Red Hat managed environment such as Red Hat\\nOpenShift Dedicated and Red Hat OpenShift Service on Amazon Web Services\\n(ROSA). 2\\\\. Installed as a self-managed Operator on a self-managed\\nenvironment, such as Red Hat OpenShift Container Platform.  \\nFor data scientists, OpenShift AI includes Jupyter and a collection of default\\nnotebook images optimized with the tools and libraries required for model\\ndevelopment, and the TensorFlow and PyTorch frameworks. Deploy and host your\\nmodels, integrate models into external applications, and export models to host\\nthem in any hybrid cloud environment. You can also accelerate your data\\nscience experiments through the use of graphics processing units (GPUs) and\\nHabana Gaudi devices. For administrators, OpenShift AI enables data science\\nworkloads in an existing Red Hat OpenShift or ROSA environment. Manage users\\nwith your existing OpenShift identity provider, and manage the resources\\navailable to notebook servers to ensure data scientists have what they require\\nto create, train, and host models. Use accelerators to reduce costs and allow\\nyour data scientists to enhance the performance of their end-to-end data\\nscience workflows using graphics processing units (GPUs) and Habana Gaudi\\ndevices. OpenShift AI offers two distributions:  \\n\\\\- A managed cloud service add-on for Red Hat OpenShift Dedicated (with a\\nCustomer Cloud Subscription for AWS or GCP) or for Red Hat OpenShift Service\\non Amazon Web Services (ROSA).For information about OpenShift AI on a Red Hat\\nmanaged environment, see Product Documentation for Red Hat OpenShift AI. \\\\-\\nSelf-managed software that you can install on-premise or on the public cloud\\nin a self-managed environment, such as OpenShift Container Platform.For\\ninformation about OpenShift AI as self-managed software on your OpenShift\\ncluster in a connected or a disconnected environment, see Product\\nDocumentation for Red Hat OpenShift AI Self-Managed.  \\nFor information about OpenShift AI supported software platforms, components,\\nand dependencies, see Supported configurations.', metadata={'Header 1': 'Chapter 1. Overview of OpenShift AI'}),\n",
       " Document(page_content='Red Hat OpenShift AI provides several features for data scientists and IT\\noperations administrators.', metadata={'Header 1': 'Chapter 2. Product features'}),\n",
       " Document(page_content='#### Containers  \\nWhile tools such as JupyterLab already offer intuitive ways for data\\nscientists to develop models on their machines, there are always inherent\\ncomplexities involved with collaboration and sharing work. Moreover, using\\nspecialized hardware such as powerful GPUs can be very expensive when you have\\nto buy and maintain your own. The Jupyter environment that is included with\\nOpenShift AI lets you take your development environment anywhere you need it\\nto be. Because all of the workloads are run as containers, collaboration is as\\neasy as sharing an image with your team members, or even simply adding it to\\nthe list of default containers that they can use. As a result, GPUs and large\\namounts of memory are significantly more accessible, since you are no longer\\nlimited by what your laptop can support.  \\n#### Integration with third-party machine learning tools  \\nWe have all run into situations where our favorite tools or services do not\\nplay well with one another. OpenShift AI is designed with flexibility in mind.\\nYou can use a wide range of open source and third-party tools with OpenShift\\nAI. These tools support the complete machine learning lifecycle, from data\\nengineering and feature extraction to model deployment and management.  \\n#### Collaboration on notebooks with Git  \\nUse Jupyter’s Git interface to work collaboratively with others, and keep good\\ntrack of the changes to your code.  \\n#### Securely built notebook images  \\nChoose from a default set of notebook images that are pre-configured with the\\ntools and libraries that you need for model development. Software stacks,\\nespecially those involved in machine learning, tend to be complex systems.\\nThere are many modules and libraries in the Python ecosystem that can be used,\\nso determining which versions of what libraries to use can be very\\nchallenging. OpenShift AI includes many packaged notebook images that have\\nbeen built with insight from data scientists and recommendation engines. You\\ncan start new projects quickly on the right foot without worrying about\\ndownloading unproven and possibly insecure images from random upstream\\nrepositories.  \\n#### Custom notebooks  \\nIn addition to notebook images provided and supported by Red Hat and\\nindependent software vendors (ISVs), you can configure custom notebook images\\nthat cater to your project’s specific requirements.  \\n#### Data science pipelines  \\nOpenShift AI supports data science pipelines for a mature and efficient way of\\nrunning your data science workloads. You can standardize and automate machine\\nlearning workflows that enable you to develop and deploy your data science\\nmodels.  \\n#### Model serving  \\nAs a data scientist, you can deploy your trained machine-learning models to\\nserve intelligent applications in production. Deploying or serving a model\\nmakes the model’s functions available as a service endpoint that can be used\\nfor testing or integration into applications. You have much control over how\\nthis serving is performed.  \\n#### Optimize your data science models with accelerators  \\nIf you work with large data sets, you can optimize the performance of your\\ndata science models in OpenShift AI with NVIDIA graphics processing units\\n(GPUs) or Habana Gaudi devices. Accelerators enable you to scale your work,\\nreduce latency, and increase productivity.', metadata={'Header 1': 'Chapter 2. Product features', 'Header 2': '2.1. Features for data scientists'}),\n",
       " Document(page_content='#### Manage users with an identity provider  \\nOpenShift AI supports the same authentication systems as your OpenShift\\ncluster. By default, OpenShift AI is accessible to all users listed in your\\nidentity provider and those users do not need a separate set of credentials to\\naccess OpenShift AI. Optionally, you can limit the set of users who have\\naccess by creating an OpenShift group that specifies a subset of users. You\\ncan also create an OpenShift group that identifies the list of users who have\\nadministrator access to OpenShift AI.  \\n#### Manage resources with OpenShift  \\nUse your existing OpenShift knowledge to configure and manage resources for\\nyour OpenShift AI users.  \\n#### Control Red Hat usage data collection  \\nChoose whether to allow Red Hat to collect data about OpenShift AI usage in\\nyour cluster. Usage data collection is enabled by default when you install\\nOpenShift AI on your OpenShift cluster.  \\n#### Apply autoscaling to your cluster to reduce usage costs  \\nUse the cluster autoscaler to adjust the size of your cluster to meet its\\ncurrent needs and optimize costs.  \\n#### Manage resource usage by stopping idle notebooks  \\nReduce resource usage in your OpenShift AI deployment by automatically\\nstopping notebook servers that have been idle for a period of time.  \\n#### Implement model-serving runtimes  \\nOpenShift AI provides support for model-serving runtimes. A model-serving\\nruntime provides integration with a specified model server and the model\\nframeworks that it supports. By default, OpenShift AI includes the OpenVINO\\nModel Server runtime. However, if this runtime doesn’t meet your needs (for\\nexample, if it doesn’t support a particular model framework), you can add your\\nown custom runtimes.  \\n#### Install in a disconnected environment  \\nOpenShift AI Self-Managed supports installation in a disconnected environment.\\nDisconnected clusters are on a restricted network, typically behind a firewall\\nand unable to reach the Internet. In this case, clusters cannot access the\\nremote registries where Red Hat provided OperatorHub sources reside. In this\\ncase, you deploy the OpenShift AI Operator to a disconnected environment by\\nusing a private registry in which you have mirrored (copied) the relevant\\nimages.  \\n#### Manage accelerators  \\nEnable NVIDIA graphics processing units (GPUs) or Habana Gaudi devices in\\nOpenShift AI and allow your data scientists to use compute-heavy workloads.', metadata={'Header 1': 'Chapter 2. Product features', 'Header 2': '2.2. Features for IT Operations administrators'}),\n",
       " Document(page_content='Data scientists and developers can try OpenShift AI and access tutorials and\\nactivities in the Red Hat Developer sandbox environment. IT operations\\nadministrators can try OpenShift AI in your own cluster with a 60-day product\\ntrial.', metadata={'Header 1': 'Chapter 3. Try It'}),\n",
       " Document(page_content='#### Managed cloud service  \\nYou have the following options for subscribing to OpenShift AI as a managed\\nservice: - For OpenShift Dedicated, subscribe through Red Hat. - For Red Hat\\nOpenShift Service on Amazon Web Services (ROSA), subscribe through Red Hat or\\nsubscribe through the AWS Marketplace.  \\n#### Self-managed software  \\nTo get Red Hat OpenShift AI as self-managed software, sign up for it with your\\nRed Hat account team.', metadata={'Header 1': 'Chapter 4. Get It'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(docs_transformed[0].page_content)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: {'Header 1': 'Introduction to Red Hat OpenShift AI'}\n",
      "Content: Red Hat OpenShift AI Self-Managed 2-latest\n",
      "\n",
      "\n",
      "\n",
      "Header: {'Header 1': 'Introduction to Red Hat OpenShift AI', 'Header 2': 'OpenShift AI is a platform for data scientists and developers of artificial'}\n",
      "Content: intelligence and machine learning (AI/ML) applications  \n",
      "Legal Notice  \n",
      "Abstract  \n",
      "Red Hat OpenShift AI is a platform for data scientists and developers of\n",
      "artificial intelligence and machine learning applications.  \n",
      "* * *\n",
      "\n",
      "\n",
      "\n",
      "Header: {'Header 1': 'Chapter 1. Overview of OpenShift AI'}\n",
      "Content: Using Red Hat OpenShift AI, users can integrate data, artificial intelligence\n",
      "and machine learning software to execute end-to-end machine learning\n",
      "workflows. OpenShift AI is supported in two configurations:  \n",
      "1\\. Installed as an Add-on to a Red Hat managed environment such as Red Hat\n",
      "OpenShift Dedicated and Red Hat OpenShift Service on Amazon Web Services\n",
      "(ROSA). 2\\. Installed as a self-managed Operator on a self-managed\n",
      "environment, such as Red Hat OpenShift Container Platform.  \n",
      "For data scien\n",
      "\n",
      "\n",
      "\n",
      "Header: {'Header 1': 'Chapter 2. Product features'}\n",
      "Content: Red Hat OpenShift AI provides several features for data scientists and IT\n",
      "operations administrators.\n",
      "\n",
      "\n",
      "\n",
      "Header: {'Header 1': 'Chapter 2. Product features', 'Header 2': '2.1. Features for data scientists'}\n",
      "Content: #### Containers  \n",
      "While tools such as JupyterLab already offer intuitive ways for data\n",
      "scientists to develop models on their machines, there are always inherent\n",
      "complexities involved with collaboration and sharing work. Moreover, using\n",
      "specialized hardware such as powerful GPUs can be very expensive when you have\n",
      "to buy and maintain your own. The Jupyter environment that is included with\n",
      "OpenShift AI lets you take your development environment anywhere you need it\n",
      "to be. Because all of the worklo\n",
      "\n",
      "\n",
      "\n",
      "Header: {'Header 1': 'Chapter 2. Product features', 'Header 2': '2.2. Features for IT Operations administrators'}\n",
      "Content: #### Manage users with an identity provider  \n",
      "OpenShift AI supports the same authentication systems as your OpenShift\n",
      "cluster. By default, OpenShift AI is accessible to all users listed in your\n",
      "identity provider and those users do not need a separate set of credentials to\n",
      "access OpenShift AI. Optionally, you can limit the set of users who have\n",
      "access by creating an OpenShift group that specifies a subset of users. You\n",
      "can also create an OpenShift group that identifies the list of users who have\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Header: {'Header 1': 'Chapter 3. Try It'}\n",
      "Content: Data scientists and developers can try OpenShift AI and access tutorials and\n",
      "activities in the Red Hat Developer sandbox environment. IT operations\n",
      "administrators can try OpenShift AI in your own cluster with a 60-day product\n",
      "trial.\n",
      "\n",
      "\n",
      "\n",
      "Header: {'Header 1': 'Chapter 4. Get It'}\n",
      "Content: #### Managed cloud service  \n",
      "You have the following options for subscribing to OpenShift AI as a managed\n",
      "service: - For OpenShift Dedicated, subscribe through Red Hat. - For Red Hat\n",
      "OpenShift Service on Amazon Web Services (ROSA), subscribe through Red Hat or\n",
      "subscribe through the AWS Marketplace.  \n",
      "#### Self-managed software  \n",
      "To get Red Hat OpenShift AI as self-managed software, sign up for it with your\n",
      "Red Hat account team.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in md_header_splits:\n",
    "    print(f\"Header: {split.metadata}\")\n",
    "    print(f\"Content: {split.page_content[:500]}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Introduction to Red Hat OpenShift AI  \\nUsing Red Hat OpenShift AI, users can integrate data, artificial intelligence and machine learning software to execute end-to-end machine learning workflows. OpenShift AI is supported in two configurations: For data scientists, OpenShift AI includes Jupyter and a collection of default notebook images optimized with the tools and libraries required for model development, and the TensorFlow and PyTorch frameworks. Deploy and host your models, integrate models into external applications, and export models to host them in any hybrid cloud environment. You can also accelerate your data science experiments through the use of graphics processing units (GPUs) and Habana Gaudi devices. For administrators, OpenShift AI enables data science workloads in an existing Red Hat OpenShift or ROSA environment. Manage users with your existing OpenShift identity provider, and manage the resources available to notebook servers to ensure data scientists have what they require to create, train, and host models. Use accelerators to reduce costs and allow your data scientists to enhance the performance of their end-to-end data science workflows using graphics processing units (GPUs) and Habana Gaudi devices. OpenShift AI offers two distributions: For information about OpenShift AI supported software platforms, components, and dependencies, see Supported configurations. Red Hat OpenShift AI provides several features for data scientists and IT operations administrators. Data scientists and developers can try OpenShift AI and access tutorials and activities in the Red Hat Developer sandbox environment. IT operations administrators can try OpenShift AI in your own cluster with a 60-day product trial.  \\nRed Hat OpenShift AI Self-Managed 2-latest  \\nOpenShift AI is a platform for data scientists and developers of artificial intelligence and machine learning (AI/ML) applications  \\nLegal Notice  \\nAbstract  \\nRed Hat OpenShift AI is a platform for data scientists and developers of artificial intelligence and machine learning applications.  \\nChapter 1. Overview of OpenShift AI  \\n1. Installed as an Add-on to a Red Hat managed environment such as Red Hat OpenShift Dedicated and Red Hat OpenShift Service on Amazon Web Services (ROSA). 2. Installed as a self-managed Operator on a self-managed environment, such as Red Hat OpenShift Container Platform.  \\n- A managed cloud service add-on for Red Hat OpenShift Dedicated (with a Customer Cloud Subscription for AWS or GCP) or for Red Hat OpenShift Service on Amazon Web Services (ROSA).For information about OpenShift AI on a Red Hat managed environment, see Product Documentation for Red Hat OpenShift AI. - Self-managed software that you can install on-premise or on the public cloud in a self-managed environment, such as OpenShift Container Platform.For information about OpenShift AI as self-managed software on your OpenShift cluster in a connected or a disconnected environment, see Product Documentation for Red Hat OpenShift AI Self-Managed.  \\nChapter 2. Product features  \\n2.1. Features for data scientists  \\nContainersWhile tools such as JupyterLab already offer intuitive ways for data scientists to develop models on their machines, there are always inherent complexities involved with collaboration and sharing work. Moreover, using specialized hardware such as powerful GPUs can be very expensive when you have to buy and maintain your own. The Jupyter environment that is included with OpenShift AI lets you take your development environment anywhere you need it to be. Because all of the workloads are run as containers, collaboration is as easy as sharing an image with your team members, or even simply adding it to the list of default containers that they can use. As a result, GPUs and large amounts of memory are significantly more accessible, since you are no longer limited by what your laptop can support.Integration with third-party machine learning toolsWe have all run into situations where our favorite tools or services do not play well with one another. OpenShift AI is designed with flexibility in mind. You can use a wide range of open source and third-party tools with OpenShift AI. These tools support the complete machine learning lifecycle, from data engineering and feature extraction to model deployment and management.Collaboration on notebooks with GitUse Jupyter’s Git interface to work collaboratively with others, and keep good track of the changes to your code.Securely built notebook imagesChoose from a default set of notebook images that are pre-configured with the tools and libraries that you need for model development. Software stacks, especially those involved in machine learning, tend to be complex systems. There are many modules and libraries in the Python ecosystem that can be used, so determining which versions of what libraries to use can be very challenging. OpenShift AI includes many packaged notebook images that have been built with insight from data scientists and recommendation engines. You can start new projects quickly on the right foot without worrying about downloading unproven and possibly insecure images from random upstream repositories.Custom notebooksIn addition to notebook images provided and supported by Red Hat and independent software vendors (ISVs), you can configure custom notebook images that cater to your project’s specific requirements.Data science pipelinesOpenShift AI supports data science pipelines for a mature and efficient way of running your data science workloads. You can standardize and automate machine learning workflows that enable you to develop and deploy your data science models.Model servingAs a data scientist, you can deploy your trained machine-learning models to serve intelligent applications in production. Deploying or serving a model makes the model’s functions available as a service endpoint that can be used for testing or integration into applications. You have much control over how this serving is performed.  \\nOptimize your data science models with acceleratorsIf you work with large data sets, you can optimize the performance of your data science models in OpenShift AI with NVIDIA graphics processing units (GPUs) or Habana Gaudi devices. Accelerators enable you to scale your work, reduce latency, and increase productivity.  \\n2.2. Features for IT Operations administrators  \\nManage users with an identity providerOpenShift AI supports the same authentication systems as your OpenShift cluster. By default, OpenShift AI is accessible to all users listed in your identity provider and those users do not need a separate set of credentials to access OpenShift AI. Optionally, you can limit the set of users who have access by creating an OpenShift group that specifies a subset of users. You can also create an OpenShift group that identifies the list of users who have administrator access to OpenShift AI.Manage resources with OpenShiftUse your existing OpenShift knowledge to configure and manage resources for your OpenShift AI users.Control Red Hat usage data collectionChoose whether to allow Red Hat to collect data about OpenShift AI usage in your cluster. Usage data collection is enabled by default when you install OpenShift AI on your OpenShift cluster.Apply autoscaling to your cluster to reduce usage costsUse the cluster autoscaler to adjust the size of your cluster to meet its current needs and optimize costs.Manage resource usage by stopping idle notebooksReduce resource usage in your OpenShift AI deployment by automatically stopping notebook servers that have been idle for a period of time.Implement model-serving runtimesOpenShift AI provides support for model-serving runtimes. A model-serving runtime provides integration with a specified model server and the model frameworks that it supports. By default, OpenShift AI includes the OpenVINO Model Server runtime. However, if this runtime doesn’t meet your needs (for example, if it doesn’t support a particular model framework), you can add your own custom runtimes.Install in a disconnected environmentOpenShift AI Self-Managed supports installation in a disconnected environment. Disconnected clusters are on a restricted network, typically behind a firewall and unable to reach the Internet. In this case, clusters cannot access the remote registries where Red Hat provided OperatorHub sources reside. In this case, you deploy the OpenShift AI Operator to a disconnected environment by using a private registry in which you have mirrored (copied) the relevant images.Manage acceleratorsEnable NVIDIA graphics processing units (GPUs) or Habana Gaudi devices in OpenShift AI and allow your data scientists to use compute-heavy workloads.  \\nChapter 3. Try It  \\nChapter 4. Get It  \\nManaged cloud serviceYou have the following options for subscribing to OpenShift AI as a managed service: - For OpenShift Dedicated, subscribe through Red Hat. - For Red Hat OpenShift Service on Amazon Web Services (ROSA), subscribe through Red Hat or subscribe through the AWS Marketplace.Self-managed softwareTo get Red Hat OpenShift AI as self-managed software, sign up for it with your Red Hat account team.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(docs[0].page_content)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: {}\n",
      "Content: Introduction to Red Hat OpenShift AI  \n",
      "Using Red Hat OpenShift AI, users can integrate data, artificial intelligence and machine learning software to execute end-to-end machine learning workflows. OpenShift AI is supported in two configurations: For data scientists, OpenShift AI includes Jupyter and a collection of default notebook images optimized with the tools and libraries required for model development, and the TensorFlow and PyTorch frameworks. Deploy and host your models, integrate models\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in html_header_splits:\n",
    "    print(f\"Header: {split.metadata}\")\n",
    "    print(f\"Content: {split.page_content[:500]}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
