{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from redhat_documentation import RedHatDocumentationLoader\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "urls = [\"https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load, parse, and transform to Markdown\n",
    "loader = RedHatDocumentationLoader(urls)\n",
    "docs = loader.load()\n",
    "html2text = Html2TextTransformer()\n",
    "md_docs = html2text.transform_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {'Header 1': 'Preface', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Preface\n",
      "\n",
      "Content:\n",
      "Learn how to use both the OpenShift command-line interface and web console to\n",
      "install Red Hat OpenShift AI Self-Managed on your OpenShift Container Platform\n",
      "cluster. To uninstall the product, learn how to use the recommended command-\n",
      "line interface (CLI) method.  \n",
      "Note  \n",
      "Red Hat recommends that you install only one instance of OpenShift AI on your\n",
      "cluster.  \n",
      "Installing the Red Hat OpenShift AI Operator on the same cluster as the Red\n",
      "Hat OpenShift AI Add-on is not recommended or supported.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 1. Architecture of OpenShift AI Self-Managed', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 1. Architecture of OpenShift AI Self-Managed\n",
      "\n",
      "Content:\n",
      "Red Hat OpenShift AI Self-Managed is an Operator that is available on a self-\n",
      "managed environment, such as Red Hat OpenShift Container Platform.  \n",
      "OpenShift AI integrates the following components and services:  \n",
      "* At the service layer:  \n",
      "-> OpenShift AI dashboard\n",
      "A customer-facing dashboard that shows available and installed applications for the OpenShift AI environment as well as learning resources such as tutorials, quick starts, and documentation. Administrative users can access functionality to manage users, clusters, notebook images, accelerator profiles, and model-serving runtimes. Data scientists can use the dashboard to create projects to organize their data science work.\n",
      "-> Model serving\n",
      "Data scientists can deploy trained machine-learning models to serve intelligent applications in production. After deployment, applications can send requests to the model using its deployed API endpoint.\n",
      "-> Data science pipelines\n",
      "Data scientists can build portable machine learning (ML) workflows with data science pipelines, using Docker containers. This enables your data scientists to automate workflows as they develop their data science models.\n",
      "-> Jupyter (self-managed)\n",
      "A self-managed application that allows data scientists to configure their own notebook server environment and develop machine learning models in JupyterLab.\n",
      "-> Distributed workloads\n",
      "Data scientists can use multiple nodes in parallel to train machine-learning models or process data more quickly. This approach significantly reduces the task completion time, and enables the use of larger datasets and more complex models.  \n",
      "Important  \n",
      "The distributed workloads feature is currently available in Red Hat OpenShift\n",
      "AI 2-latest as Technology Preview feature only. Technology Preview features\n",
      "are not supported with Red Hat production service level agreements (SLAs) and\n",
      "might not be functionally complete. Red Hat does not recommend using them in\n",
      "production. These features provide early access to upcoming product features,\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 1. Architecture of OpenShift AI Self-Managed', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 1. Architecture of OpenShift AI Self-Managed\n",
      "\n",
      "Content:\n",
      "are not supported with Red Hat production service level agreements (SLAs) and\n",
      "might not be functionally complete. Red Hat does not recommend using them in\n",
      "production. These features provide early access to upcoming product features,\n",
      "enabling customers to test functionality and provide feedback during the\n",
      "development process.  \n",
      "For more information about the support scope of Red Hat Technology Preview\n",
      "features, see Technology Preview Features Support Scope.  \n",
      "* At the management layer:  \n",
      "-> The Red Hat OpenShift AI Operator\n",
      "A meta-operator that deploys and maintains all components and sub-operators that are part of OpenShift AI.\n",
      "-> Monitoring services\n",
      "Prometheus gathers metrics from OpenShift AI for monitoring purposes.  \n",
      "When you install the Red Hat OpenShift AI Operator in the OpenShift Container\n",
      "Platform cluster, the following new projects are created:  \n",
      "* The `redhat-ods-operator` project contains the Red Hat OpenShift AI Operator.\n",
      "* The `redhat-ods-applications` project installs the dashboard and other required components of OpenShift AI.\n",
      "* The `redhat-ods-monitoring` project contains services for monitoring.\n",
      "* The `rhods-notebooks` project is where notebook environments are deployed by default.  \n",
      "You or your data scientists must create additional projects for the\n",
      "applications that will use your machine learning models.  \n",
      "Do not install independent software vendor (ISV) applications in namespaces\n",
      "associated with OpenShift AI.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI\n",
      "\n",
      "Content:\n",
      "Red Hat OpenShift AI is a platform for data scientists and developers of\n",
      "artificial intelligence (AI) applications. It provides a fully supported\n",
      "environment that lets you rapidly develop, train, test, and deploy machine\n",
      "learning models on-premises and/or in the public cloud.  \n",
      "OpenShift AI is provided as a managed cloud service add-on for Red Hat\n",
      "OpenShift or as self-managed software that you can install on-premise or in\n",
      "the public cloud on OpenShift.  \n",
      "For information about installing OpenShift AI as self-managed software on your\n",
      "OpenShift cluster in a disconnected environment, see Installing and\n",
      "uninstalling OpenShift AI Self-Managed in a disconnected environment. For\n",
      "information about installing OpenShift AI as a managed cloud service add-on,\n",
      "see Installing and uninstalling OpenShift AI.  \n",
      "Installing OpenShift AI involves the following high-level tasks:  \n",
      "1. Confirm that your OpenShift Container Platform cluster meets all requirements. See Requirements for OpenShift AI Self-Managed.\n",
      "2. Add administrative users for OpenShift Container Platform. See Adding administrative users for OpenShift Container Platform.\n",
      "3. Install the Red Hat OpenShift AI Operator. See Installing the Red Hat OpenShift AI Operator.\n",
      "4. Install OpenShift AI components. See Installing and managing Red Hat OpenShift AI components.\n",
      "5. Configure user and administrator groups to provide user access to OpenShift AI. See Adding users.\n",
      "6. Access the OpenShift AI dashboard. See Accessing the OpenShift AI dashboard.\n",
      "7. Optionally, enable graphics processing units (GPUs) in OpenShift AI to ensure that your data scientists can use compute-heavy workloads in their models. See Enabling GPU support in OpenShift AI.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.1. Requirements for OpenShift AI Self-Managed', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.1. Requirements for OpenShift AI Self-Managed\n",
      "\n",
      "Content:\n",
      "Your environment must meet certain requirements to receive support for Red Hat\n",
      "OpenShift AI.  \n",
      "Installation requirements  \n",
      "You must meet the following requirements before you are able to install\n",
      "OpenShift AI on your Red Hat OpenShift Container Platform cluster.  \n",
      "* Product subscriptions  \n",
      "* A subscription for Red Hat OpenShift AI Self-Managed  \n",
      "Contact your Red Hat account manager to purchase new subscriptions. If you do\n",
      "not yet have an account manager, complete the form at\n",
      "https://www.redhat.com/en/contact to request one.  \n",
      "* An OpenShift Container Platform cluster 4.12 or greater  \n",
      "* Use an existing cluster or create a new cluster by following the OpenShift Container Platform documentation: OpenShift Container Platform installation overview.  \n",
      "Your cluster must have at least 2 worker nodes with at least 8 CPUs and 32 GiB\n",
      "RAM available for OpenShift AI to use when you install the Operator. To ensure\n",
      "that OpenShift AI is usable, additional cluster resources are required beyond\n",
      "the minimum requirements.  \n",
      "* A default storage class that can be dynamically provisioned must be configured.  \n",
      "Confirm that a default storage class is configured by running the `oc get\n",
      "storageclass` command. If no storage classes are noted with `(default)` beside\n",
      "the name, follow the OpenShift Container Platform documentation to configure a\n",
      "default storage class: Changing the default storage class. For more\n",
      "information about dynamic provisioning, see Dynamic provisioning.  \n",
      "* Open Data Hub must not be installed on the cluster.  \n",
      "For more information about managing the machines that make up an OpenShift\n",
      "cluster, see Overview of machine management.  \n",
      "* An identity provider configured for OpenShift Container Platform  \n",
      "Access to the cluster as a user with the `cluster-admin` role; the `kubeadmin`\n",
      "user is not allowed.  \n",
      "Red Hat OpenShift AI supports the same authentication systems as Red Hat\n",
      "OpenShift Container Platform. See Understanding identity provider\n",
      "configuration for more information on configuring identity providers.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.1. Requirements for OpenShift AI Self-Managed', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.1. Requirements for OpenShift AI Self-Managed\n",
      "\n",
      "Content:\n",
      "user is not allowed.  \n",
      "Red Hat OpenShift AI supports the same authentication systems as Red Hat\n",
      "OpenShift Container Platform. See Understanding identity provider\n",
      "configuration for more information on configuring identity providers.  \n",
      "* Internet access  \n",
      "Along with Internet access, the following domains must be accessible during\n",
      "the installation of OpenShift AI Self-Managed:  \n",
      "* cdn.redhat.com\n",
      "* subscription.rhn.redhat.com\n",
      "* registry.access.redhat.com\n",
      "* registry.redhat.io\n",
      "* quay.io  \n",
      "For CUDA-based images, the following domains must be accessible:  \n",
      "* ngc.download.nvidia.cn\n",
      "* developer.download.nvidia.com\n",
      "* OpenShift Pipelines operator installation  \n",
      "* The Red Hat OpenShift Pipelines operator enables support for installation of pipelines in a self-managed environment.  \n",
      "Before you use data science pipelines in OpenShift AI, you must install the\n",
      "Red Hat OpenShift Pipelines Operator. For more information, see Installing\n",
      "OpenShift Pipelines. If your deployment is in a disconnected self-managed\n",
      "environment, see Red Hat OpenShift Pipelines Operator in a restricted\n",
      "environment.  \n",
      "* Before you can execute a pipeline in a disconnected environment, you must mirror any images used by your pipelines to a private registry.\n",
      "* You can store your pipeline artifacts in an Amazon Web Services (AWS) Simple Storage Service (S3) bucket to ensure that you do not consume local storage. To do this, you must first configure write access to your S3 bucket on your AWS account.  \n",
      "If you do not have access to Amazon S3 storage, you must configure your own\n",
      "storage solution for use with pipelines.  \n",
      "* Install KServe dependencies  \n",
      "To support KServe components, you must install dependent Operators, including\n",
      "the Red Hat OpenShift Serverless and Red Hat OpenShift Service Mesh Operators.\n",
      "For more information, see Serving large models.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.2. Adding administrative users for OpenShift Container Platform', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.2. Adding administrative users for OpenShift Container Platform\n",
      "\n",
      "Content:\n",
      "Before you can install and configure OpenShift AI for your data scientist\n",
      "users, you must define administrative users. Only users with the `cluster-\n",
      "admin` role can install and configure OpenShift AI.  \n",
      "For more information about creating a cluster admin user, see Creating a\n",
      "cluster admin.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.3. Installing the Red Hat OpenShift AI Operator', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.3. Installing the Red Hat OpenShift AI Operator\n",
      "\n",
      "Content:\n",
      "This section shows how to install the Red Hat OpenShift AI Operator on your\n",
      "OpenShift Container Platform cluster using the command-line interface (CLI)\n",
      "and the OpenShift web console.  \n",
      "Note  \n",
      "If you want to upgrade from a previous version of OpenShift AI rather than\n",
      "performing a new installation, see Upgrading OpenShift AI.  \n",
      "Note  \n",
      "If your OpenShift cluster uses a proxy to access the Internet, you can\n",
      "configure the proxy settings for the Red Hat OpenShift AI Operator. See\n",
      "Overriding proxy settings of an Operator for more information.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.3. Installing the Red Hat OpenShift AI Operator', 'Header 3': '2.3.1. Installing the Red Hat OpenShift AI Operator by using the CLI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.3. Installing the Red Hat OpenShift AI Operator / 2.3.1. Installing the Red Hat OpenShift AI Operator by using the CLI\n",
      "\n",
      "Content:\n",
      "The following procedure shows how to use the OpenShift command-line interface\n",
      "(CLI) to install the Red Hat OpenShift AI Operator on your OpenShift Container\n",
      "Platform cluster. You must install the Operator before you can install\n",
      "OpenShift AI components on the cluster.  \n",
      "Prerequisites  \n",
      "* You have a running OpenShift Container Platform cluster, version 4.12 or greater, configured with a default storage class that can be dynamically provisioned.\n",
      "* You have cluster administrator privileges for your OpenShift Container Platform cluster.\n",
      "* You have downloaded and installed the OpenShift command-line interface (CLI). See Installing the OpenShift CLI.\n",
      "* To support KServe components, you installed the dependent Operators, including the Red Hat OpenShift Serverless and Red Hat OpenShift Service Mesh Operators. For more information, see Serving large models.  \n",
      "Procedure  \n",
      "1. Open a new terminal window.\n",
      "2. In the OpenShift command-line interface (CLI), log in to your OpenShift Container Platform cluster as a cluster administrator, as shown in the following example:  \n",
      "$ oc login _< openshift_cluster_url>_ -u _< admin_username>_ -p _< password>_  \n",
      "3. Create a namespace for installation of the Operator by performing the following actions:  \n",
      "1. Create a namespace YAML file, for example, `rhods-operator-namespace.yaml`.  \n",
      "```yaml\n",
      "apiVersion: v1\n",
      "kind: Namespace\n",
      "metadata:\n",
      "name: redhat-ods-operator\n",
      "```  \n",
      "2. Create the namespace in your OpenShift Container Platform cluster.  \n",
      "$ oc create -f rhods-operator-namespace.yaml  \n",
      "You see output similar to the following:  \n",
      "namespace/redhat-ods-operator created  \n",
      "4. Create an operator group for installation of the Operator by performing the following actions:  \n",
      "1. Create an `OperatorGroup` object custom resource (CR) file, for example, `rhods-operator-group.yaml`.  \n",
      "```yaml\n",
      "apiVersion: operators.coreos.com/v1\n",
      "kind: OperatorGroup\n",
      "metadata:\n",
      "name: rhods-operator\n",
      "namespace: redhat-ods-operator\n",
      "```  \n",
      "2. Create the `OperatorGroup` object in your OpenShift Container Platform cluster.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.3. Installing the Red Hat OpenShift AI Operator', 'Header 3': '2.3.1. Installing the Red Hat OpenShift AI Operator by using the CLI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.3. Installing the Red Hat OpenShift AI Operator / 2.3.1. Installing the Red Hat OpenShift AI Operator by using the CLI\n",
      "\n",
      "Content:\n",
      "```yaml\n",
      "apiVersion: operators.coreos.com/v1\n",
      "kind: OperatorGroup\n",
      "metadata:\n",
      "name: rhods-operator\n",
      "namespace: redhat-ods-operator\n",
      "```  \n",
      "2. Create the `OperatorGroup` object in your OpenShift Container Platform cluster.  \n",
      "$ oc create -f rhods-operator-group.yaml  \n",
      "You see output similar to the following:  \n",
      "operatorgroup.operators.coreos.com/rhods-operator created  \n",
      "5. Create a subscription for installation of the Operator by performing the following actions:  \n",
      "1. Create a `Subscription` object CR file, for example, `rhods-operator-subscription.yaml`.  \n",
      "```yaml\n",
      "apiVersion: operators.coreos.com/v1alpha1\n",
      "kind: Subscription\n",
      "metadata:\n",
      "name: rhods-operator\n",
      "namespace: redhat-ods-operator\n",
      "spec:\n",
      "name: rhods-operator\n",
      "channel: stable\n",
      "source: redhat-operators\n",
      "sourceNamespace: openshift-marketplace\n",
      "```  \n",
      "Channel| Support| Release frequency| Recommended environment\n",
      "---|---|---|---\n",
      "`fast` |  One month of full support  |  Every month  |  Production environments with access to the latest product features.\n",
      "Select this streaming channel with automatic upgrades to avoid manually\n",
      "upgrading every month.\n",
      "`stable` |  Three months of full support  |  Every three months  |  Production environments with stability prioritized over new feature availability.\n",
      "Select this streaming channel with automatic upgrades to access the latest\n",
      "stable release and avoid manually upgrading.\n",
      "`stable-x.y` |  Seven months of full support  |  Every three months  |  Production environments with stability prioritized over new feature availability.\n",
      "Select numbered stable channels (such as `stable-2-latest`) to plan and\n",
      "execute the upgrade to the next stable release while keeping your deployment\n",
      "under full support.\n",
      "`eus-x.y` |  Seven months of full support followed by Extended Update Support for eleven months  |  Every nine months  |  Enterprise-grade environments that cannot upgrade within a seven month window.\n",
      "Select this streaming channel if you prioritize stability over new feature\n",
      "availability.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.3. Installing the Red Hat OpenShift AI Operator', 'Header 3': '2.3.1. Installing the Red Hat OpenShift AI Operator by using the CLI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.3. Installing the Red Hat OpenShift AI Operator / 2.3.1. Installing the Red Hat OpenShift AI Operator by using the CLI\n",
      "\n",
      "Content:\n",
      "Select this streaming channel if you prioritize stability over new feature\n",
      "availability.\n",
      "`alpha` |  One month of full support  |  Every month  |  Development environments with early-access features that might not be functionally complete.\n",
      "Select this channel to use early-access features that enable you to test\n",
      "functionality and provide feedback during the development process. Early-\n",
      "access features are not supported with Red Hat production service level\n",
      "agreements (SLAs).\n",
      "For more information about the support scope of Red Hat Technology Preview\n",
      "features, see Technology Preview Features Support Scope. For more information\n",
      "about the support scope of Red Hat Developer Preview features, see Developer\n",
      "Preview Features Support Scope.\n",
      "Note  \n",
      "The `embedded` and `beta` channels are legacy channels that will be removed in\n",
      "a future release. Do not select the `embedded` or `beta` channels for a new\n",
      "installation of the Operator.  \n",
      "2. As described in the preceding step, ensure that the subscription channel you specify is appropriate for your organization’s requirements.\n",
      "3. Create the `Subscription` object in your OpenShift Container Platform cluster to install the Operator.  \n",
      "$ oc create -f rhods-operator-subscription.yaml  \n",
      "You see output similar to the following:  \n",
      "subscription.operators.coreos.com/rhods-operator created  \n",
      "Verification  \n",
      "* In the OpenShift Container Platform web console, click Operators → Installed Operators and confirm that the Red Hat OpenShift AI Operator shows one of the following statuses:  \n",
      "* `Installing` \\- installation is in progress; wait for this to change to `Succeeded`. This might take several minutes.\n",
      "* `Succeeded` \\- installation is successful.\n",
      "* In the web console, click Home → Projects and confirm that the following project namespaces are visible and listed as `Active`:  \n",
      "* `redhat-ods-applications`\n",
      "* `redhat-ods-monitoring`\n",
      "* `redhat-ods-operator`  \n",
      "Additional resources  \n",
      "* Installing and managing Red Hat OpenShift AI components\n",
      "* Adding users\n",
      "* Adding Operators to a cluster\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.3. Installing the Red Hat OpenShift AI Operator', 'Header 3': '2.3.2. Installing the Red Hat OpenShift AI Operator by using the web', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.3. Installing the Red Hat OpenShift AI Operator / 2.3.2. Installing the Red Hat OpenShift AI Operator by using the web\n",
      "\n",
      "Content:\n",
      "console  \n",
      "The following procedure shows how to use the OpenShift Container Platform web\n",
      "console to install the Red Hat OpenShift AI Operator on your cluster. You must\n",
      "install the Operator before you can install OpenShift AI components on the\n",
      "cluster.  \n",
      "Prerequisites  \n",
      "* You have a running OpenShift Container Platform cluster, version 4.12 or greater, configured with a default storage class that can be dynamically provisioned.\n",
      "* You have cluster administrator privileges for your OpenShift Container Platform cluster.\n",
      "* To support KServe components, you installed the dependent Operators, including the Red Hat OpenShift Serverless and Red Hat OpenShift Service Mesh Operators. For more information, see Serving large models.  \n",
      "Procedure  \n",
      "1. Log in to the OpenShift Container Platform web console as a cluster administrator.\n",
      "2. In the web console, click Operators → OperatorHub.\n",
      "3. On the OperatorHub page, locate the Red Hat OpenShift AI Operator by scrolling through available Operators or by typing _Red Hat OpenShift AI_ into the Filter by keyword box.\n",
      "4. Select the Operator to display additional information.\n",
      "5. Read the information about the Operator and click Install.\n",
      "6. For Update channel, select a value of `fast`, `stable`, `stable-2-latest`, `eus-2-latest`, or `alpha`. The following table describes these channels. For more information, including the lifecycle associated with each of the available subscription channels, see Red Hat OpenShift AI Self-Managed Life Cycle.  \n",
      "Channel| Support| Release frequency| Recommended environment\n",
      "---|---|---|---\n",
      "`fast` |  One month of full support  |  Every month  |  Production environments with access to the latest product features.\n",
      "Select this streaming channel with automatic upgrades to avoid manually\n",
      "upgrading every month.\n",
      "`stable` |  Three months of full support  |  Every three months  |  Production environments with stability prioritized over new feature availability.\n",
      "Select this streaming channel with automatic upgrades to access the latest\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.3. Installing the Red Hat OpenShift AI Operator', 'Header 3': '2.3.2. Installing the Red Hat OpenShift AI Operator by using the web', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.3. Installing the Red Hat OpenShift AI Operator / 2.3.2. Installing the Red Hat OpenShift AI Operator by using the web\n",
      "\n",
      "Content:\n",
      "upgrading every month.\n",
      "`stable` |  Three months of full support  |  Every three months  |  Production environments with stability prioritized over new feature availability.\n",
      "Select this streaming channel with automatic upgrades to access the latest\n",
      "stable release and avoid manually upgrading.\n",
      "`stable-x.y` |  Seven months of full support  |  Every three months  |  Production environments with stability prioritized over new feature availability.\n",
      "Select numbered stable channels (such as `stable-2-latest`) to plan and\n",
      "execute the upgrade to the next stable release while keeping your deployment\n",
      "under full support.\n",
      "`eus-x.y` |  Seven months of full support followed by Extended Update Support for eleven months  |  Every nine months  |  Enterprise-grade environments that cannot upgrade within a seven month window.\n",
      "Select this streaming channel if you prioritize stability over new feature\n",
      "availability.\n",
      "`alpha` |  One month of full support  |  Every month  |  Development environments with early-access features that might not be functionally complete.\n",
      "Select this channel to use early-access features that enable you to test\n",
      "functionality and provide feedback during the development process. Early-\n",
      "access features are not supported with Red Hat production service level\n",
      "agreements (SLAs).\n",
      "For more information about the support scope of Red Hat Technology Preview\n",
      "features, see Technology Preview Features Support Scope. For more information\n",
      "about the support scope of Red Hat Developer Preview features, see Developer\n",
      "Preview Features Support Scope.\n",
      "Note  \n",
      "The `embedded` and `beta` channels are legacy channels that will be removed in\n",
      "a future release. Do not select the `embedded` or `beta` channels for a new\n",
      "installation of the Operator.  \n",
      "7. For Installation mode, observe that the only available value is `All namespaces on the cluster (default)`. This installation mode makes the Operator available to all namespaces in the cluster.\n",
      "8. For Installed Namespace, select `redhat-ods-operator (Operator recommended)`.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.3. Installing the Red Hat OpenShift AI Operator', 'Header 3': '2.3.2. Installing the Red Hat OpenShift AI Operator by using the web', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.3. Installing the Red Hat OpenShift AI Operator / 2.3.2. Installing the Red Hat OpenShift AI Operator by using the web\n",
      "\n",
      "Content:\n",
      "8. For Installed Namespace, select `redhat-ods-operator (Operator recommended)`.\n",
      "9. Under Update approval, select either `Automatic` or `Manual`.\n",
      "10. Click Install.  \n",
      "An installation pane opens. When the installation finishes, a checkmark\n",
      "appears beside the Operator name in the installation pane.  \n",
      "Verification  \n",
      "* In the OpenShift Container Platform web console, click Operators → Installed Operators and confirm that the Red Hat OpenShift AI Operator shows one of the following statuses:  \n",
      "* `Installing` \\- installation is in progress; wait for this to change to `Succeeded`. This might take several minutes.\n",
      "* `Succeeded` \\- installation is successful.\n",
      "* In the web console, click Home → Projects and confirm that the following project namespaces are visible and listed as `Active`:  \n",
      "* `redhat-ods-applications`\n",
      "* `redhat-ods-monitoring`\n",
      "* `redhat-ods-operator`  \n",
      "Additional resources  \n",
      "* Installing and managing Red Hat OpenShift AI components\n",
      "* Adding users\n",
      "* Adding Operators to a cluster\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.4. Installing and managing Red Hat OpenShift AI components', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.4. Installing and managing Red Hat OpenShift AI components\n",
      "\n",
      "Content:\n",
      "The following procedures show how to use the command-line interface (CLI) and\n",
      "OpenShift Container Platform web console to install and manage components of\n",
      "Red Hat OpenShift AI on your OpenShift Container Platform cluster.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.4. Installing and managing Red Hat OpenShift AI components', 'Header 3': '2.4.1. Installing Red Hat OpenShift AI components by using the CLI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.4. Installing and managing Red Hat OpenShift AI components / 2.4.1. Installing Red Hat OpenShift AI components by using the CLI\n",
      "\n",
      "Content:\n",
      "The following procedure shows how to use the OpenShift command-line interface\n",
      "(CLI) to install specific components of Red Hat OpenShift AI on your OpenShift\n",
      "Container Platform cluster.  \n",
      "Important  \n",
      "The following procedure describes how to create and configure a\n",
      "`DataScienceCluster` object to install Red Hat OpenShift AI components as part\n",
      "of a _new_ installation. However, if you upgraded from version 1 of OpenShift\n",
      "AI (previously OpenShift Data Science), the upgrade process automatically\n",
      "created a default `DataScienceCluster` object. If you upgraded from version\n",
      "2.4 to 2.5, the upgrade process uses the settings from the 2.4 version’s\n",
      "`DataScienceCluster` object. To inspect the default `DataScienceCluster`\n",
      "object and change the installation status of Red Hat OpenShift AI components,\n",
      "see Updating the installation status of Red Hat OpenShift AI components by\n",
      "using the web console.  \n",
      "Prerequisites  \n",
      "* To support the KServe component, you installed dependent Operators, including the Red Hat OpenShift Serverless and Red Hat OpenShift Service Mesh Operators. For more information, see Serving large models.\n",
      "* The Red Hat OpenShift AI Operator is installed on your OpenShift Container Platform cluster. See Installing the Red Hat OpenShift AI Operator.\n",
      "* You have cluster administrator privileges for your OpenShift Container Platform cluster.\n",
      "* You have downloaded and installed the OpenShift command-line interface (CLI). See Installing the OpenShift CLI.  \n",
      "Procedure  \n",
      "1. Open a new terminal window.\n",
      "2. In the OpenShift command-line interface (CLI), log in to your on your OpenShift Container Platform cluster as a cluster administrator, as shown in the following example:  \n",
      "$ oc login _< openshift_cluster_url>_ -u _< admin_username>_ -p _< password>_  \n",
      "3. Create a `DataScienceCluster` object custom resource (CR) file, for example, `rhods-operator-dsc.yaml`.  \n",
      "```yaml\n",
      "apiVersion: datasciencecluster.opendatahub.io/v1\n",
      "kind: DataScienceCluster\n",
      "metadata:\n",
      "name: default-dsc\n",
      "spec:\n",
      "components:\n",
      "codeflare:\n",
      "managementState: Removed\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.4. Installing and managing Red Hat OpenShift AI components', 'Header 3': '2.4.1. Installing Red Hat OpenShift AI components by using the CLI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.4. Installing and managing Red Hat OpenShift AI components / 2.4.1. Installing Red Hat OpenShift AI components by using the CLI\n",
      "\n",
      "Content:\n",
      "```yaml\n",
      "apiVersion: datasciencecluster.opendatahub.io/v1\n",
      "kind: DataScienceCluster\n",
      "metadata:\n",
      "name: default-dsc\n",
      "spec:\n",
      "components:\n",
      "codeflare:\n",
      "managementState: Removed\n",
      "dashboard:\n",
      "managementState: Removed\n",
      "datasciencepipelines:\n",
      "managementState: Removed\n",
      "kserve:\n",
      "managementState: Removed\n",
      "modelmeshserving:\n",
      "managementState: Removed\n",
      "ray:\n",
      "managementState: Removed\n",
      "workbenches:\n",
      "managementState: Removed\n",
      "```  \n",
      "4. In the `spec.components` section of the CR, for each OpenShift AI component shown, set the value of the `managementState` field to either `Managed` or `Removed`. These values are defined as follows:  \n",
      "-> Managed\n",
      "The Operator actively manages the component, installs it, and tries to keep it active. The Operator will upgrade the component only if it is safe to do so.\n",
      "-> Removed\n",
      "The Operator actively manages the component but does not install it. If the component is already installed, the Operator will try to remove it.\n",
      "Important  \n",
      "* To learn how to install the KServe component, which is used by the single model serving platform to serve large models, see Serving large models.\n",
      "* The CodeFlare and KubeRay components are Technology Preview features only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process. For more information about the support scope of Red Hat Technology Preview features, see Technology Preview Features Support Scope.\n",
      "* To learn how to configure the distributed workloads feature that uses the CodeFlare and KubeRay components, see Configuring distributed workloads.\n",
      "5. Create the `DataScienceCluster` object in your OpenShift Container Platform cluster to install the specified OpenShift AI components.  \n",
      "$ oc create -f rhods-operator-dsc.yaml  \n",
      "You see output similar to the following:\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.4. Installing and managing Red Hat OpenShift AI components', 'Header 3': '2.4.1. Installing Red Hat OpenShift AI components by using the CLI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.4. Installing and managing Red Hat OpenShift AI components / 2.4.1. Installing Red Hat OpenShift AI components by using the CLI\n",
      "\n",
      "Content:\n",
      "5. Create the `DataScienceCluster` object in your OpenShift Container Platform cluster to install the specified OpenShift AI components.  \n",
      "$ oc create -f rhods-operator-dsc.yaml  \n",
      "You see output similar to the following:  \n",
      "datasciencecluster.datasciencecluster.opendatahub.io/default created  \n",
      "Verification  \n",
      "* Confirm that there is a running pod for each component:  \n",
      "1. In the OpenShift Container Platform web console, click Workloads → Pods.\n",
      "2. In the Project list at the top of the page, select `redhat-ods-applications`.\n",
      "3. In the applications namespace, confirm that there are running pods for each of the OpenShift AI components that you installed.\n",
      "* Confirm the status of all installed components:  \n",
      "1. In the OpenShift Container Platform web console, click Operators → Installed Operators.\n",
      "2. Click the Red Hat OpenShift AI Operator.\n",
      "3. Click the Data Science Cluster tab and select the `DataScienceCluster` object called `default-dsc`.\n",
      "4. Select the YAML tab.\n",
      "5. In the `installedComponents` section, confirm that the components you installed have a status value of `true`.  \n",
      "Note  \n",
      "If a component shows with the `component-name: {}` format in the\n",
      "`spec.components` section of the CR, the component is not installed.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.4. Installing and managing Red Hat OpenShift AI components', 'Header 3': '2.4.2. Installing Red Hat OpenShift AI components by using the web console', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.4. Installing and managing Red Hat OpenShift AI components / 2.4.2. Installing Red Hat OpenShift AI components by using the web console\n",
      "\n",
      "Content:\n",
      "The following procedure shows how to use the OpenShift Container Platform web\n",
      "console to install specific components of Red Hat OpenShift AI on your\n",
      "cluster.  \n",
      "Important  \n",
      "The following procedure describes how to create and configure a\n",
      "`DataScienceCluster` object to install Red Hat OpenShift AI components as part\n",
      "of a _new_ installation. However, if you upgraded from version 1 of OpenShift\n",
      "AI (previously OpenShift Data Science), the upgrade process automatically\n",
      "created a default `DataScienceCluster` object. If you upgraded from a previous\n",
      "minor version, the upgrade process used the settings from the previous\n",
      "version’s `DataScienceCluster` object. To inspect the `DataScienceCluster`\n",
      "object and change the installation status of Red Hat OpenShift AI components,\n",
      "see Updating the installation status of Red Hat OpenShift AI components by\n",
      "using the web console.  \n",
      "Prerequisites  \n",
      "* To support the KServe component, you installed dependent Operators, including the Red Hat OpenShift Serverless and Red Hat OpenShift Service Mesh Operators. For more information, see Serving large models.\n",
      "* The Red Hat OpenShift AI Operator is installed on your OpenShift Container Platform cluster. See Installing the Red Hat OpenShift AI Operator.\n",
      "* You have cluster administrator privileges for your OpenShift Container Platform cluster.  \n",
      "Procedure  \n",
      "1. Log in to the OpenShift Container Platform web console as a cluster administrator.\n",
      "2. In the web console, click Operators → Installed Operators and then click the Red Hat OpenShift AI Operator.\n",
      "3. Create a `DataScienceCluster` object to install OpenShift AI components by performing the following actions:  \n",
      "1. Click the Data Science Cluster tab.\n",
      "2. Click Create DataScienceCluster.\n",
      "3. For Configure via, select YAML view.  \n",
      "An embedded YAML editor opens showing a default custom resource (CR) for the\n",
      "`DataScienceCluster` object.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.4. Installing and managing Red Hat OpenShift AI components', 'Header 3': '2.4.2. Installing Red Hat OpenShift AI components by using the web console', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.4. Installing and managing Red Hat OpenShift AI components / 2.4.2. Installing Red Hat OpenShift AI components by using the web console\n",
      "\n",
      "Content:\n",
      "1. Click the Data Science Cluster tab.\n",
      "2. Click Create DataScienceCluster.\n",
      "3. For Configure via, select YAML view.  \n",
      "An embedded YAML editor opens showing a default custom resource (CR) for the\n",
      "`DataScienceCluster` object.  \n",
      "4. In the `spec.components` section of the CR, for each OpenShift AI component shown, set the value of the `managementState` field to either `Managed` or `Removed`. These values are defined as follows:  \n",
      "-> Managed\n",
      "The Operator actively manages the component, installs it, and tries to keep it active. The Operator will upgrade the component only if it is safe to do so.\n",
      "-> Removed\n",
      "The Operator actively manages the component but does not install it. If the component is already installed, the Operator will try to remove it.\n",
      "Important  \n",
      "* To learn how to install the KServe component, which is used by the single model serving platform to serve large models, see Serving large models.\n",
      "* The CodeFlare and KubeRay components are Technology Preview features only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process. For more information about the support scope of Red Hat Technology Preview features, see Technology Preview Features Support Scope.\n",
      "* To learn how to configure the distributed workloads feature that uses the CodeFlare and KubeRay components, see Configuring distributed workloads.\n",
      "4. Click Create.  \n",
      "Verification  \n",
      "* Confirm that there is a running pod for each component:  \n",
      "1. In the OpenShift Container Platform web console, click Workloads → Pods.\n",
      "2. In the Project list at the top of the page, select `redhat-ods-applications`.\n",
      "3. In the applications namespace, confirm that there are running pods for each of the OpenShift AI components that you installed.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.4. Installing and managing Red Hat OpenShift AI components', 'Header 3': '2.4.2. Installing Red Hat OpenShift AI components by using the web console', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.4. Installing and managing Red Hat OpenShift AI components / 2.4.2. Installing Red Hat OpenShift AI components by using the web console\n",
      "\n",
      "Content:\n",
      "2. In the Project list at the top of the page, select `redhat-ods-applications`.\n",
      "3. In the applications namespace, confirm that there are running pods for each of the OpenShift AI components that you installed.\n",
      "* Confirm the status of all installed components:  \n",
      "1. In the OpenShift Container Platform web console, click Operators → Installed Operators.\n",
      "2. Click the Red Hat OpenShift AI Operator.\n",
      "3. Click the Data Science Cluster tab and select the `DataScienceCluster` object called `default-dsc`.\n",
      "4. Select the YAML tab.\n",
      "5. In the `installedComponents` section, confirm that the components you installed have a status value of `true`.  \n",
      "Note  \n",
      "If a component shows with the `component-name: {}` format in the\n",
      "`spec.components` section of the CR, the component is not installed.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.4. Installing and managing Red Hat OpenShift AI components', 'Header 3': '2.4.3. Updating the installation status of Red Hat OpenShift AI components', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.4. Installing and managing Red Hat OpenShift AI components / 2.4.3. Updating the installation status of Red Hat OpenShift AI components\n",
      "\n",
      "Content:\n",
      "by using the web console  \n",
      "The following procedure shows how to use the OpenShift Container Platform web\n",
      "console to update the installation status of components of Red Hat OpenShift\n",
      "AI on your OpenShift Container Platform cluster.  \n",
      "Important  \n",
      "If you upgraded from version 1 to version 2 of OpenShift AI, the upgrade\n",
      "process automatically created a default `DataScienceCluster` object and\n",
      "enabled several components of OpenShift AI. If you upgraded from a previous\n",
      "minor version, the upgrade process used the settings from the previous\n",
      "version’s `DataScienceCluster` object.  \n",
      "The following procedure describes how to edit the `DataScienceCluster` object:  \n",
      "* Change the installation status of the existing Red Hat OpenShift AI components\n",
      "* Add additional components to the `DataScienceCluster` object that were not available in the previous version of OpenShift AI.  \n",
      "Prerequisites  \n",
      "* To support the KServe component, you installed dependent Operators, including the Red Hat OpenShift Serverless and Red Hat OpenShift Service Mesh Operators. For more information, see Serving large models.\n",
      "* The Red Hat OpenShift AI Operator is installed on your OpenShift Container Platform cluster.\n",
      "* You have cluster administrator privileges for your OpenShift Container Platform cluster.  \n",
      "Procedure  \n",
      "1. Log in to the OpenShift Container Platform web console as a cluster administrator.\n",
      "2. In the web console, click Operators → Installed Operators and then click the Red Hat OpenShift AI Operator.\n",
      "3. Click the Data Science Cluster tab.\n",
      "4. On the DataScienceClusters page, click the `default` object.\n",
      "5. Click the YAML tab.  \n",
      "An embedded YAML editor opens showing the custom resource (CR) file for the\n",
      "`DataScienceCluster` object.  \n",
      "6. In the `spec.components` section of the CR, for each OpenShift AI component shown, set the value of the `managementState` field to either `Managed` or `Removed`. These values are defined as follows:  \n",
      "Note  \n",
      "If a component shows with the `component-name: {}` format in the\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.4. Installing and managing Red Hat OpenShift AI components', 'Header 3': '2.4.3. Updating the installation status of Red Hat OpenShift AI components', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.4. Installing and managing Red Hat OpenShift AI components / 2.4.3. Updating the installation status of Red Hat OpenShift AI components\n",
      "\n",
      "Content:\n",
      "Note  \n",
      "If a component shows with the `component-name: {}` format in the\n",
      "`spec.components` section of the CR, the component is not installed.  \n",
      "-> Managed\n",
      "The Operator actively manages the component, installs it, and tries to keep it active. The Operator will upgrade the component only if it is safe to do so.\n",
      "-> Removed\n",
      "The Operator actively manages the component but does not install it. If the component is already installed, the Operator will try to remove it.\n",
      "Important  \n",
      "* To learn how to install the KServe component, which is used by the single model serving platform to serve large models, see Serving large models.\n",
      "* If they are not already present in the CR file, you can install the CodeFlare and KubeRay features by adding components called `codeflare` and `ray` to the `spec.components` section of the CR and setting the `managementState` field for the components to `Managed`.\n",
      "* The CodeFlare and KubeRay components are Technology Preview features only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process. For more information about the support scope of Red Hat Technology Preview features, see Technology Preview Features Support Scope.\n",
      "* To learn how to configure the distributed workloads feature that uses the CodeFlare and KubeRay components, see Configuring distributed workloads.\n",
      "7. Click Save.  \n",
      "For any components that you updated, OpenShift AI initiates a rollout that\n",
      "affects all pods to use the updated image.  \n",
      "Verification  \n",
      "* Confirm that there is a running pod for each component:  \n",
      "1. In the OpenShift Container Platform web console, click Workloads → Pods.\n",
      "2. In the Project list at the top of the page, select `redhat-ods-applications`.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 2. Installing and deploying OpenShift AI', 'Header 2': '2.4. Installing and managing Red Hat OpenShift AI components', 'Header 3': '2.4.3. Updating the installation status of Red Hat OpenShift AI components', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 2. Installing and deploying OpenShift AI / 2.4. Installing and managing Red Hat OpenShift AI components / 2.4.3. Updating the installation status of Red Hat OpenShift AI components\n",
      "\n",
      "Content:\n",
      "Verification  \n",
      "* Confirm that there is a running pod for each component:  \n",
      "1. In the OpenShift Container Platform web console, click Workloads → Pods.\n",
      "2. In the Project list at the top of the page, select `redhat-ods-applications`.\n",
      "3. In the applications namespace, confirm that there are running pods for each of the OpenShift AI components that you installed.\n",
      "* Confirm the status of all installed components:  \n",
      "1. In the OpenShift Container Platform web console, click Operators → Installed Operators.\n",
      "2. Click the Red Hat OpenShift AI Operator.\n",
      "3. Click the Data Science Cluster tab and select the `DataScienceCluster` object called `default-dsc`.\n",
      "4. Select the YAML tab.\n",
      "5. In the `installedComponents` section, confirm that the components you installed have a status value of `true`.  \n",
      "Note  \n",
      "If a component shows with the `component-name: {}` format in the\n",
      "`spec.components` section of the CR, the component is not installed.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates\n",
      "\n",
      "Content:\n",
      "Certificates are used by various components in OpenShift Container Platform to\n",
      "validate access to the cluster. For clusters that rely on self-signed\n",
      "certificates, you can add those self-signed certificates to a cluster-wide\n",
      "Certificate Authority (CA) bundle and use the CA bundle in Red Hat OpenShift\n",
      "AI. You can also use self-signed certificates in a custom CA bundle that is\n",
      "separate from the cluster-wide bundle. Administrators can add a CA bundle,\n",
      "remove a CA bundle from all namespaces, remove a CA bundle from individual\n",
      "namespaces, or manually manage certificate changes instead of the system.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.1. Understanding certificates in OpenShift AI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.1. Understanding certificates in OpenShift AI\n",
      "\n",
      "Content:\n",
      "For OpenShift Container Platform clusters that rely on self-signed\n",
      "certificates, you can add those self-signed certificates to a cluster-wide\n",
      "Certificate Authority (CA) bundle (`ca-bundle.crt`) and use the CA bundle in\n",
      "Red Hat OpenShift AI. You can also use self-signed certificates in a custom CA\n",
      "bundle (`odh-ca-bundle.crt`) that is separate from the cluster-wide bundle.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.1. Understanding certificates in OpenShift AI', 'Header 3': '3.1.1. How CA bundles are injected', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.1. Understanding certificates in OpenShift AI / 3.1.1. How CA bundles are injected\n",
      "\n",
      "Content:\n",
      "After installing OpenShift AI, the Red Hat OpenShift AI Operator automatically\n",
      "creates an empty `odh-trusted-ca-bundle` configuration file (ConfigMap), and\n",
      "the Cluster Network Operator (CNO) injects the cluster-wide CA bundle into the\n",
      "`odh-trusted-ca-bundle` configMap with the label \"config.openshift.io/inject-\n",
      "trusted-cabundle\". The components deployed in the affected namespaces are\n",
      "responsible for mounting this configMap as a volume in the deployment pods.  \n",
      "apiVersion: v1\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "labels:\n",
      "app.kubernetes.io/part-of: opendatahub-operator\n",
      "config.openshift.io/inject-trusted-cabundle: 'true'\n",
      "name: odh-trusted-ca-bundle  \n",
      "After the CNO operator injects the bundle, it updates the ConfigMap with the\n",
      "`ca-bundle.crt` file containing the certificates.  \n",
      "apiVersion: v1\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "labels:\n",
      "app.kubernetes.io/part-of: opendatahub-operator\n",
      "config.openshift.io/inject-trusted-cabundle: 'true'\n",
      "name: odh-trusted-ca-bundle\n",
      "data:\n",
      "ca-bundle.crt: |\n",
      "<BUNDLE OF CLUSTER-WIDE CERTIFICATES>\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.1. Understanding certificates in OpenShift AI', 'Header 3': '3.1.2. How the ConfigMap is managed', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.1. Understanding certificates in OpenShift AI / 3.1.2. How the ConfigMap is managed\n",
      "\n",
      "Content:\n",
      "By default, the Red Hat OpenShift AI Operator manages the `odh-trusted-ca-\n",
      "bundle` ConfigMap. If you want to manage or remove the `odh-trusted-ca-bundle`\n",
      "ConfigMap, or add a custom CA bundle (`odh-ca-bundle.crt`) separate from the\n",
      "cluster-wide CA bundle (`ca-bundle.crt`), you can use the `trustedCABundle`\n",
      "property in the Operator’s DSC Initialization (DSCI) object.  \n",
      "spec:\n",
      "trustedCABundle:\n",
      "managementState: Managed\n",
      "customCABundle: \"\"  \n",
      "In the Operator’s DSCI object, you can set the\n",
      "`spec.trustedCABundle.managementState` field to the following values:  \n",
      "* `Managed`: The Red Hat OpenShift AI Operator manages the `odh-trusted-ca-bundle` ConfigMap and adds it to all non-reserved existing and new namespaces (the ConfigMap is not added to any reserved or system namespaces, such as `default`, `openshift-\\*` or `kube-*`). The ConfigMap is automatically updated to reflect any changes made to the `customCABundle` field. This is the default value after installing Red Hat OpenShift AI.\n",
      "* `Removed`: The Red Hat OpenShift AI Operator removes the `odh-trusted-ca-bundle` ConfigMap (if present) and disables the creation of the ConfigMap in new namespaces. If you change this field from `Managed` to `Removed`, the `odh-trusted-ca-bundle` ConfigMap is also deleted from namespaces. This is the default value after upgrading Red Hat OpenShift AI from 2.7 or earlier versions to 2-latest.\n",
      "* `Unmanaged`: The Red Hat OpenShift AI Operator does not manage the `odh-trusted-ca-bundle` ConfigMap, allowing for an administrator to manage it instead. Changing the `managementState` from `Managed` to `Unmanaged` does not remove the `odh-trusted-ca-bundle` ConfigMap, but the ConfigMap is not updated if you make changes to the `customCABundle` field.  \n",
      "In the Operator’s DSCI object, you can add a custom certificate to the\n",
      "`spec.trustedCABundle.customCABundle` field. This adds the `odh-ca-bundle.crt`\n",
      "file containing the certificates to the `odh-trusted-ca-bundle` ConfigMap, as\n",
      "shown in the following example:  \n",
      "apiVersion: v1\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.1. Understanding certificates in OpenShift AI', 'Header 3': '3.1.2. How the ConfigMap is managed', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.1. Understanding certificates in OpenShift AI / 3.1.2. How the ConfigMap is managed\n",
      "\n",
      "Content:\n",
      "`spec.trustedCABundle.customCABundle` field. This adds the `odh-ca-bundle.crt`\n",
      "file containing the certificates to the `odh-trusted-ca-bundle` ConfigMap, as\n",
      "shown in the following example:  \n",
      "apiVersion: v1\n",
      "kind: ConfigMap\n",
      "metadata:\n",
      "labels:\n",
      "app.kubernetes.io/part-of: opendatahub-operator\n",
      "config.openshift.io/inject-trusted-cabundle: 'true'\n",
      "name: odh-trusted-ca-bundle\n",
      "data:\n",
      "ca-bundle.crt: |\n",
      "<BUNDLE OF CLUSTER-WIDE CERTIFICATES>\n",
      "odh-ca-bundle.crt: |\n",
      "<BUNDLE OF CUSTOM CERTIFICATES>\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.2. Adding a CA bundle', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.2. Adding a CA bundle\n",
      "\n",
      "Content:\n",
      "There are two ways to add a Certificate Authority (CA) bundle to OpenShift AI.\n",
      "You can use one or both of these methods:  \n",
      "* For OpenShift Container Platform clusters that rely on self-signed certificates, you can add those self-signed certificates to a cluster-wide Certificate Authority (CA) bundle (`ca-bundle.crt`) and use the CA bundle in Red Hat OpenShift AI. To use this method, log in to the OpenShift Container Platform as a cluster administrator and follow the steps as described in Configuring the cluster-wide proxy during installation.\n",
      "* You can use self-signed certificates in a custom CA bundle (`odh-ca-bundle.crt`) that is separate from the cluster-wide bundle. To use this method, follow the steps in this section.  \n",
      "Prerequisites  \n",
      "* You have admin access to the `DSCInitialization` resources in the OpenShift Container Platform cluster.\n",
      "* You installed the OpenShift command line interface (`oc`) as described in Get Started with the CLI.\n",
      "* You are working in a new installation of Red Hat OpenShift AI. If you upgraded Red Hat OpenShift AI, see Adding a CA bundle after upgrading.  \n",
      "Procedure  \n",
      "1. Log in to the OpenShift Container Platform.\n",
      "2. Click Operators → Installed Operators and then click the Red Hat OpenShift AI Operator.\n",
      "3. Click the DSC Initialization tab.\n",
      "4. Click the default-dsci object.\n",
      "5. Click the YAML tab.\n",
      "6. In the `spec` section, add the custom certificate to the `customCABundle` field for `trustedCABundle`, as shown in the following example:  \n",
      "spec:\n",
      "trustedCABundle:\n",
      "managementState: Managed\n",
      "customCABundle: |\n",
      "-----BEGIN CERTIFICATE-----\n",
      "examplebundle123\n",
      "-----END CERTIFICATE-----  \n",
      "7. Click Save.  \n",
      "Verification  \n",
      "* If you are using a cluster-wide CA bundle, run the following command to verify that all non-reserved namespaces contain the `odh-trusted-ca-bundle` ConfigMap:  \n",
      "$ oc get configmaps --all-namespaces -l app.kubernetes.io/part-of=opendatahub-operator | grep odh-trusted-ca-bundle\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.2. Adding a CA bundle', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.2. Adding a CA bundle\n",
      "\n",
      "Content:\n",
      "$ oc get configmaps --all-namespaces -l app.kubernetes.io/part-of=opendatahub-operator | grep odh-trusted-ca-bundle  \n",
      "* If you are using a custom CA bundle, run the following command to verify that a non-reserved namespace contains the `odh-trusted-ca-bundle` ConfigMap and that the ConfigMap contains your `customCABundle` value. In the following command, _example-namespace_ is the non-reserved namespace and _examplebundle123_ is the customCABundle value.  \n",
      "$ oc get configmap odh-trusted-ca-bundle -n example-namespace -o yaml | grep examplebundle123\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.3. Removing a CA bundle', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.3. Removing a CA bundle\n",
      "\n",
      "Content:\n",
      "You can remove a Certificate Authority (CA) bundle from all non-reserved\n",
      "namespaces in OpenShift AI. This process changes the default configuration and\n",
      "disables the creation of the `odh-trusted-ca-bundle` configuration file\n",
      "(ConfigMap), as described in _Understanding certificates in OpenShift AI_.  \n",
      "Note  \n",
      "The `odh-trusted-ca-bundle` ConfigMaps are only deleted from namespaces when\n",
      "you set the `managementState` of `trustedCABundle` to `Removed`; deleting the\n",
      "DSC Initialization does not delete the ConfigMaps.  \n",
      "To remove a CA bundle from a single namespace only, see _Removing a CA bundle\n",
      "from a namespace_.  \n",
      "Prerequisites  \n",
      "* You have cluster administrator privileges for your OpenShift Container Platform cluster.\n",
      "* You installed the OpenShift command line interface (`oc`) as described in Get Started with the CLI.  \n",
      "Procedure  \n",
      "1. In the OpenShift Container Platform web console, click Operators → Installed Operators and then click the Red Hat OpenShift AI Operator.\n",
      "2. Click the DSC Initialization tab.\n",
      "3. Click the default-dsci object.\n",
      "4. Click the YAML tab.\n",
      "5. In the `spec` section, change the value of the `managementState` field for `trustedCABundle` to `Removed`:  \n",
      "spec:\n",
      "trustedCABundle:\n",
      "managementState: Removed  \n",
      "6. Click Save.  \n",
      "Verification  \n",
      "* Run the following command to verify that the `odh-trusted-ca-bundle` ConfigMap has been removed from all namespaces:  \n",
      "$ oc get configmaps --all-namespaces | grep odh-trusted-ca-bundle  \n",
      "The command should not return any ConfigMaps.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.4. Removing a CA bundle from a namespace', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.4. Removing a CA bundle from a namespace\n",
      "\n",
      "Content:\n",
      "You can remove a custom Certificate Authority (CA) bundle from individual\n",
      "namespaces in OpenShift AI. This process disables the creation of the `odh-\n",
      "trusted-ca-bundle` configuration file (ConfigMap) for the specified namespace\n",
      "only.  \n",
      "To remove a certificate bundle from all namespaces, see _Removing a CA\n",
      "bundle_.  \n",
      "Prerequisites  \n",
      "* You have cluster administrator privileges for your OpenShift Container Platform cluster.\n",
      "* You installed the OpenShift command line interface (`oc`) as described in Get Started with the CLI.  \n",
      "Procedure  \n",
      "* Run the following command to remove a CA bundle from a namespace. In the following command, _example-namespace_ is the non-reserved namespace.  \n",
      "$ oc annotate ns example-namespace security.opendatahub.io/inject-trusted-ca-bundle=false  \n",
      "Verification  \n",
      "* Run the following command to verify that the CA bundle has been removed from the namespace. In the following command, _example-namespace_ is the non-reserved namespace.  \n",
      "$ oc get configmap odh-trusted-ca-bundle -n example-namespace  \n",
      "The command should return `configmaps \"odh-trusted-ca-bundle\" not found`.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.5. Managing certificates', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.5. Managing certificates\n",
      "\n",
      "Content:\n",
      "After installing OpenShift AI, the Red Hat OpenShift AI Operator creates the\n",
      "`odh-trusted-ca-bundle` configuration file (ConfigMap) that contains the\n",
      "trusted CA bundle and adds it to all new and existing non-reserved namespaces\n",
      "in the cluster. By default, the Red Hat OpenShift AI Operator manages the\n",
      "`odh-trusted-ca-bundle` ConfigMap and automatically updates it if any changes\n",
      "are made to the CA bundle. You can choose to manage the `odh-trusted-ca-\n",
      "bundle` ConfigMap instead of allowing the Red Hat OpenShift AI Operator to\n",
      "manage it.  \n",
      "Prerequisites  \n",
      "* You have cluster administrator privileges for your OpenShift Container Platform cluster.  \n",
      "Procedure  \n",
      "1. In the OpenShift Container Platform web console, click Operators → Installed Operators and then click the Red Hat OpenShift AI Operator.\n",
      "2. Click the DSC Initialization tab.\n",
      "3. Click the default-dsci object.\n",
      "4. Click the YAML tab.\n",
      "5. In the `spec` section, change the value of the `managementState` field for `trustedCABundle` to `Unmanaged`, as shown:  \n",
      "spec:\n",
      "trustedCABundle:\n",
      "managementState: Unmanaged  \n",
      "6. Click Save.  \n",
      "Note that changing the `managementState` from `Managed` to `Unmanaged` does\n",
      "not remove the `odh-trusted-ca-bundle` ConfigMap, but the ConfigMap is not\n",
      "updated if you make changes to the `customCABundle` field.  \n",
      "Verification  \n",
      "1. In the `spec` section, set or change the value of the `customCABundle` field for `trustedCABundle`, for example:  \n",
      "spec:\n",
      "trustedCABundle:\n",
      "managementState: Unmanaged\n",
      "customCABundle: example123  \n",
      "2. Click Save.\n",
      "3. Click Workloads → ConfigMaps.\n",
      "4. Select a project from the project list.\n",
      "5. Click the `odh-trusted-ca-bundle` ConfigMap.\n",
      "6. Click the YAML tab and verify that the value of the `customCABundle` field did not update.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.6. Using self-signed certificates with OpenShift AI components', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.6. Using self-signed certificates with OpenShift AI components\n",
      "\n",
      "Content:\n",
      "Some OpenShift AI components have additional options or required configuration\n",
      "for self-signed certificates.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 3. Working with certificates', 'Header 2': '3.6. Using self-signed certificates with OpenShift AI components', 'Header 3': '3.6.1. Using certificates with data science pipelines', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 3. Working with certificates / 3.6. Using self-signed certificates with OpenShift AI components / 3.6.1. Using certificates with data science pipelines\n",
      "\n",
      "Content:\n",
      "If you want to use self-signed certificates, you have added them to a central\n",
      "Certificate Authority (CA) bundle as described in Working with certificates\n",
      "(for disconnected environments, see Working with certificates).  \n",
      "No additional configuration is necessary to use those certificates with data\n",
      "science pipelines.  \n",
      "#### 3.6.1.1. Providing a CA bundle only for data science pipelines  \n",
      "Perform the following steps to provide a Certificate Authority (CA) bundle\n",
      "just for data science pipelines.  \n",
      "Procedure  \n",
      "1. Log in to OpenShift Container Platform.\n",
      "2. From Workloads → ConfigMaps, create a ConfigMap with the required bundle in the same data science project or namespace as the target data science pipeline:  \n",
      "kind: ConfigMap\n",
      "apiVersion: v1\n",
      "metadata:\n",
      "name: custom-ca-bundle\n",
      "data:\n",
      "ca-bundle.crt: |\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'contents of ca-bundle.crt', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / contents of ca-bundle.crt\n",
      "\n",
      "Content:\n",
      "3. Add the following snippet to the `.spec.apiserver.caBundle` field of the underlying Data Science Pipelines Application (DSPA):  \n",
      "apiVersion: datasciencepipelinesapplications.opendatahub.io/v1alpha1\n",
      "kind: DataSciencePipelinesApplication\n",
      "metadata:\n",
      "name: data-science-pipelines-definition\n",
      "spec:\n",
      "...\n",
      "apiServer:\n",
      "...\n",
      "cABundle:\n",
      "configMapName: custom-ca-bundle\n",
      "configMapKey: ca-bundle.crt  \n",
      "The pipeline server pod redeploys with the updated bundle and uses it in the\n",
      "newly created pipeline pods.  \n",
      "Verification  \n",
      "Perform the following steps to confirm that your CA bundle was successfully\n",
      "mounted.  \n",
      "1. Log in to the OpenShift Container Platform console.\n",
      "2. Go to the OpenShift Container Platform project that corresponds to the data science project.\n",
      "3. Click the Pods tab.\n",
      "4. Click the pipeline server pod with the `ds-pipeline-pipelines-definition-<hash>` prefix.\n",
      "5. Click Terminal.\n",
      "6. Enter `cat /dsp-custom-certs/dsp-ca.crt`.\n",
      "7. Verify that your CA bundle is present within this file.  \n",
      "You can also confirm that your CA bundle was successfully mounted by using the\n",
      "CLI:  \n",
      "1. In a terminal window, log in to the OpenShift cluster where OpenShift AI is deployed.  \n",
      "oc login  \n",
      "2. Set the `dspa` value:  \n",
      "dspa=pipelines-definition  \n",
      "3. Set the `dsProject` value, replacing `$YOUR_DS_PROJECT` with the name of your data science project:  \n",
      "dsProject=$YOUR_DS_PROJECT  \n",
      "4. Set the `pod` value:  \n",
      "pod=$(oc get pod -n ${dsProject} -l app=ds-pipeline-${dspa} --no-headers | awk '{print $1}')  \n",
      "5. Display the contents of the `/dsp-custom-certs/dsp-ca.crt` file:  \n",
      "oc -n ${dsProject} exec $pod -- cat /dsp-custom-certs/dsp-ca.crt  \n",
      "6. Verify that your CA bundle is present within this file.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'contents of ca-bundle.crt', 'Header 3': '3.6.2. Using certificates with workbenches', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / contents of ca-bundle.crt / 3.6.2. Using certificates with workbenches\n",
      "\n",
      "Content:\n",
      "Important  \n",
      "Self-signed certificates apply to workbenches that you create after\n",
      "configuring self-signed certificates centrally as described in Working with\n",
      "certificates (for disconnected environments, see Working with certificates.\n",
      "There is no change to workbenches that you created before configuring self-\n",
      "signed certificates.  \n",
      "#### 3.6.2.1. Creating data science pipelines with Elyra and self-signed\n",
      "certificates  \n",
      "To create pipelines using a workbench that contains the Elyra extension and\n",
      "which uses self-signed certificates, see the Workbench workaround for\n",
      "executing a pipeline using Elyra in a disconnected environment knowledgebase\n",
      "article.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 4. Accessing the dashboard', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 4. Accessing the dashboard\n",
      "\n",
      "Content:\n",
      "After you have installed OpenShift AI and added users, you can access the URL\n",
      "for your OpenShift AI console and share the URL with the users to let them log\n",
      "in and work on their models.  \n",
      "Prerequisites  \n",
      "* You have installed OpenShift AI on your OpenShift Container Platform cluster.\n",
      "* You have added at least one user to the user group for OpenShift AI.  \n",
      "Procedure  \n",
      "1. Log in to OpenShift Container Platform web console.\n",
      "2. Click the application launcher (  ).\n",
      "3. Right-click on Red Hat OpenShift AI and copy the URL for your OpenShift AI instance.\n",
      "4. Provide this instance URL to your data scientists to let them log in to OpenShift AI.  \n",
      "Verification  \n",
      "* Confirm that you and your users can log in to OpenShift AI by using the instance URL.  \n",
      "Additional resources  \n",
      "* Logging in to OpenShift AI\n",
      "* Adding users\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 5. Enabling GPU support in OpenShift AI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 5. Enabling GPU support in OpenShift AI\n",
      "\n",
      "Content:\n",
      "Optionally, to ensure that your data scientists can use compute-heavy\n",
      "workloads in their models, you can enable graphics processing units (GPUs) in\n",
      "OpenShift AI.  \n",
      "Important  \n",
      "If you are using OpenShift AI in a disconnected self-managed environment, see\n",
      "Enabling GPU support in OpenShift AI instead.  \n",
      "Prerequisites  \n",
      "* You have logged in to your OpenShift Container Platform cluster.\n",
      "* You have the `cluster-admin` role in your OpenShift Container Platform cluster.  \n",
      "Procedure  \n",
      "1. To enable GPU support on an OpenShift cluster, follow the instructions here: NVIDIA GPU Operator on Red Hat OpenShift Container Platform in the NVIDIA documentation.\n",
      "2. Delete the migration-gpu-status ConfigMap.  \n",
      "1. In the OpenShift Container Platform web console, switch to the Administrator perspective.\n",
      "2. Set the Project to All Projects or redhat-ods-applications to ensure you can see the appropriate ConfigMap.\n",
      "3. Search for the migration-gpu-status ConfigMap.\n",
      "4. Click the action menu (⋮) and select Delete ConfigMap from the list.  \n",
      "The Delete ConfigMap dialog appears.  \n",
      "5. Inspect the dialog and confirm that you are deleting the correct ConfigMap.\n",
      "6. Click Delete.\n",
      "3. Restart the dashboard replicaset.  \n",
      "1. In the OpenShift Container Platform web console, switch to the Administrator perspective.\n",
      "2. Click Workloads → Deployments.\n",
      "3. Set the Project to All Projects or redhat-ods-applications to ensure you can see the appropriate deployment.\n",
      "4. Search for the rhods-dashboard deployment.\n",
      "5. Click the action menu (⋮) and select Restart Rollout from the list.\n",
      "6. Wait until the Status column indicates that all pods in the rollout have fully restarted.  \n",
      "Verification  \n",
      "* The NVIDIA GPU Operator appears on the Operators → Installed Operators page in the OpenShift Container Platform web console.\n",
      "* The reset migration-gpu-status instance is present in the Instances tab on the `AcceleratorProfile` custom resource definition (CRD) details page.  \n",
      "After installing the NVIDIA GPU Operator, create an accelerator profile as\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 5. Enabling GPU support in OpenShift AI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 5. Enabling GPU support in OpenShift AI\n",
      "\n",
      "Content:\n",
      "* The reset migration-gpu-status instance is present in the Instances tab on the `AcceleratorProfile` custom resource definition (CRD) details page.  \n",
      "After installing the NVIDIA GPU Operator, create an accelerator profile as\n",
      "described in Working with accelerator profiles.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 6. Uninstalling Red Hat OpenShift AI Self-Managed', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 6. Uninstalling Red Hat OpenShift AI Self-Managed\n",
      "\n",
      "Content:\n",
      "This section shows how to use the OpenShift command-line interface (CLI) to\n",
      "uninstall the Red Hat OpenShift AI Operator and any OpenShift AI components\n",
      "installed and managed by the Operator.  \n",
      "Note  \n",
      "Using the CLI is the recommended way to uninstall the Operator. Depending on\n",
      "your version of OpenShift Container Platform, using the web console to perform\n",
      "the uninstallation might not prompt you to uninstall all associated\n",
      "components. This could leave you unclear about the final state of your\n",
      "cluster.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 6. Uninstalling Red Hat OpenShift AI Self-Managed', 'Header 2': '6.1. Understanding the uninstallation process', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 6. Uninstalling Red Hat OpenShift AI Self-Managed / 6.1. Understanding the uninstallation process\n",
      "\n",
      "Content:\n",
      "Installing Red Hat OpenShift AI created several custom resource instances on\n",
      "your OpenShift Container Platform cluster for various components of OpenShift\n",
      "AI. After installation, users likely created several additional resources\n",
      "while using OpenShift AI. Uninstalling OpenShift AI removes the resources that\n",
      "were created by the Operator, but retains the resources created by users to\n",
      "prevent inadvertently deleting information you might want.  \n",
      "What is deleted  \n",
      "Uninstalling OpenShift AI removes the following resources from your OpenShift\n",
      "Container Platform cluster:  \n",
      "* `DataScienceCluster` custom resource instance\n",
      "* `DSCInitialization` custom resource instance\n",
      "* `FeatureTracker` custom resource instances created during or after installation\n",
      "* `ServiceMesh` custom resource instance created by the Operator during or after installation\n",
      "* `KNativeServing` custom resource instance created by the Operator during or after installation\n",
      "* `redhat-ods-applications`, `redhat-ods-monitoring`, and `rhods-notebooks` namespaces created by the Operator\n",
      "* Workloads in the `rhods-notebooks` namespace\n",
      "* `Subscription`, `ClusterServiceVersion`, and `InstallPlan` objects\n",
      "* `KfDef` object (version 1 Operator only)  \n",
      "What might remain  \n",
      "Uninstalling OpenShift AI retains the following resources in your OpenShift\n",
      "Container Platform cluster:  \n",
      "* Data science projects created by users\n",
      "* Custom resource instances created by users\n",
      "* Custom resource definitions (CRDs) created by users or by the Operator  \n",
      "While these resources might still remain in your OpenShift Container Platform\n",
      "cluster, they are not functional. After uninstalling, Red Hat recommends that\n",
      "you review the data science projects and custom resources in your OpenShift\n",
      "Container Platform cluster and delete anything no longer in use to prevent\n",
      "potential issues, such as pipelines that cannot run, notebooks that cannot be\n",
      "undeployed, or models that cannot be undeployed.  \n",
      "Additional resources  \n",
      "Operator Lifecycle Manager (OLM) uninstall documentation\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 6. Uninstalling Red Hat OpenShift AI Self-Managed', 'Header 2': '6.2. Uninstalling OpenShift AI Self-Managed by using the CLI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 6. Uninstalling Red Hat OpenShift AI Self-Managed / 6.2. Uninstalling OpenShift AI Self-Managed by using the CLI\n",
      "\n",
      "Content:\n",
      "The following procedure shows how to use the OpenShift command-line interface\n",
      "(CLI) to uninstall the Red Hat OpenShift AI Operator and any OpenShift AI\n",
      "components installed and managed by the Operator.  \n",
      "Prerequisites  \n",
      "* You have cluster administrator privileges for your OpenShift Container Platform cluster.\n",
      "* You have downloaded and installed the OpenShift command-line interface (CLI). See Installing the OpenShift CLI.\n",
      "* You have backed up the persistent disks or volumes used by your persistent volume claims (PVCs).  \n",
      "Procedure  \n",
      "1. Open a new terminal window.\n",
      "2. In the OpenShift command-line interface (CLI), log in to your OpenShift Container Platform cluster as a cluster administrator, as shown in the following example:  \n",
      "$ oc login _< openshift_cluster_url>_ -u system:admin  \n",
      "3. Create a `ConfigMap` object for deletion of the Red Hat OpenShift AI Operator.  \n",
      "$ oc create configmap delete-self-managed-odh -n redhat-ods-operator  \n",
      "4. To delete the `rhods-operator`, set the `addon-managed-odh-delete` label to `true`.  \n",
      "$ oc label configmap/delete-self-managed-odh api.openshift.com/addon-managed-odh-delete=true -n redhat-ods-operator  \n",
      "5. When all objects associated with the Operator are removed, delete the `redhat-ods-operator` project.  \n",
      "1. Set an environment variable for the `redhat-ods-applications` project.  \n",
      "$ PROJECT_NAME=redhat-ods-applications  \n",
      "2. Wait until the `redhat-ods-applications` project has been deleted.  \n",
      "$ while oc get project $PROJECT_NAME &> /dev/null; do\n",
      "echo \"The $PROJECT_NAME project still exists\"\n",
      "sleep 1\n",
      "done\n",
      "echo \"The $PROJECT_NAME project no longer exists\"  \n",
      "When the `redhat-ods-applications` project has been deleted, you see the\n",
      "following output.  \n",
      "The redhat-ods-applications project no longer exists  \n",
      "3. When the `redhat-ods-applications` project has been deleted, delete the `redhat-ods-operator` project.  \n",
      "$ oc delete namespace redhat-ods-operator  \n",
      "Verification  \n",
      "* Confirm that the `rhods-operator` subscription no longer exists.\n",
      "\n",
      "\n",
      "Metadata: {'Header 1': 'Chapter 6. Uninstalling Red Hat OpenShift AI Self-Managed', 'Header 2': '6.2. Uninstalling OpenShift AI Self-Managed by using the CLI', 'source': 'https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2-latest/html-single/installing_and_uninstalling_openshift_ai_self-managed/index', 'title': 'Installing and uninstalling OpenShift AI Self-Managed'}\n",
      "Page Content:\n",
      "-------------\n",
      "Section: Installing and uninstalling OpenShift AI Self-Managed / Chapter 6. Uninstalling Red Hat OpenShift AI Self-Managed / 6.2. Uninstalling OpenShift AI Self-Managed by using the CLI\n",
      "\n",
      "Content:\n",
      "3. When the `redhat-ods-applications` project has been deleted, delete the `redhat-ods-operator` project.  \n",
      "$ oc delete namespace redhat-ods-operator  \n",
      "Verification  \n",
      "* Confirm that the `rhods-operator` subscription no longer exists.  \n",
      "$ oc get subscriptions --all-namespaces | grep rhods-operator  \n",
      "* Confirm that the following projects no longer exist.  \n",
      "* `redhat-ods-applications`\n",
      "* `redhat-ods-monitoring`\n",
      "* `redhat-ods-operator`\n",
      "* `rhods-notebooks`  \n",
      "$ oc get namespaces | grep -e redhat-ods* -e rhods*  \n",
      "Note  \n",
      "The `rhods-notebooks` project was created only if you installed the\n",
      "workbenches component of OpenShift AI. See Installing and managing Red Hat\n",
      "OpenShift AI components.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Markdown splitter config\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    "    strip_headers=True\n",
    "    )\n",
    "\n",
    "# Markdown split\n",
    "new_splits = []\n",
    "for doc in md_docs:\n",
    "    md_header_splits = markdown_splitter.split_text(doc.page_content)\n",
    "    for split in md_header_splits:\n",
    "        split.metadata = split.metadata | doc.metadata\n",
    "\n",
    "    new_splits.extend(md_header_splits)\n",
    "\n",
    "# Char-level splitter config\n",
    "chunk_size = 2048\n",
    "chunk_overlap = 256\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "# Char-level split\n",
    "splits = text_splitter.split_documents(new_splits)\n",
    "\n",
    "for split in splits:\n",
    "    content_header = f\"Section: {split.metadata['title']}\"\n",
    "    for header_name in [\"Header 1\", \"Header 2\", \"Header 3\"]:\n",
    "        if header_name in split.metadata:\n",
    "            content_header += f\" / {split.metadata[header_name]}\"\n",
    "    content_header += \"\\n\\nContent:\\n\"\n",
    "    split.page_content = content_header + split.page_content\n",
    "\n",
    "for split in splits:\n",
    "    print(f\"Metadata: {split.metadata}\")\n",
    "    print(f\"Page Content:\\n-------------\\n{split.page_content}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
